#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
docling_text_to_modento.py — v2.21

TXT (Docling) -> Modento-compliant JSON

What's new vs v2.20 (Priority Improvements):
  • Priority 1.1: OCR Auto-Detection - Automatically detects and processes scanned PDFs
  • Priority 2.1: Multi-Field Label Splitting - Enhanced detection of multi-subfield patterns
  • Priority 2.2: Grid Column Headers - Option A implementation (prefix approach)
  • Priority 2.3: Inline Checkbox Detection - Enhanced mid-sentence checkbox recognition
  • Fixed module exports for proper test compatibility
  • All implementations use generic patterns - NO form-specific hardcoding
  
Previous versions:
  • v2.20/Archivev19 Fix 4: Never treat lines with question marks as section headings
  • v2.19/Archivev19 Fix 3: Inline checkbox field title extraction preserves labels
  • v2.18/Archivev19 Fix 1-2: Single-word field labels, multi-line questions
"""

from __future__ import annotations

import argparse
import copy
import json
import re
import sys
from difflib import SequenceMatcher
from collections import Counter, defaultdict
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set

# Import from modularized components
from .modules.text_preprocessing import (
    normalize_glyphs_line,
    collapse_spaced_letters_any,
    collapse_spaced_caps,
    read_text_file,
    is_heading,
    is_category_header,
    normalize_section_name,
    detect_repeated_lines,
    is_address_block,
    scrub_headers_footers,
    coalesce_soft_wraps
)
from .modules.grid_parser import (
    looks_like_grid_header,
    detect_table_layout,
    parse_table_to_questions,
    chunk_by_columns,
    detect_column_boundaries,
    detect_multicolumn_checkbox_grid,
    parse_multicolumn_checkbox_grid,
    extract_text_for_checkbox,
    extract_text_only_items_at_columns
)
from .modules.template_catalog import (
    TemplateCatalog,
    FindResult,
    merge_with_template,
    _dedupe_keys_dicts,
    _norm_text,
    _slug_key_norm,
    _token_set_ratio,
    _is_conditions_control,
    _sanitize_words_set,
    _alias_tokens_ok,
    _sanitize_words
)
# Patch 7 Phase 1: Import utility functions from question_parser
from .modules.question_parser import (
    slugify,
    clean_token,
    normalize_opt_name,
    clean_option_text,
    clean_field_title,
    make_option,
    classify_input_type,
    classify_date_input,
)

# ---------- Paths

DEFAULT_IN_DIR = "output"
DEFAULT_OUT_DIR = "JSONs"

# ---------- Regex / tokens

CHECKBOX_ANY = r"(?:\[\s*\]|\[x\]|☐|☑|□|■|❒|◻|✓|✔|✗|✘)"
BULLET_RE = re.compile(r"^\s*(?:[-*•·]|" + CHECKBOX_ANY + r")\s+")
CHECKBOX_MARK_RE = re.compile(r"^\s*(" + CHECKBOX_ANY + r")\s+")

INLINE_CHOICE_RE = re.compile(
    rf"(?:^|\s){CHECKBOX_ANY}\s*([^\[\]•·\-\u2022]+?)(?=(?:\s*{CHECKBOX_ANY}|\s*[•·\-]|$))"
)

YESNO_SET = {"yes", "no", "y", "n"}

PHONE_RE   = re.compile(r"\b(phone|cell|mobile|telephone)\b", re.I)
EMAIL_RE   = re.compile(r"\bemail\b", re.I)
ZIP_RE     = re.compile(r"\b(zip|postal)\b", re.I)
SSN_RE     = re.compile(r"\b(ssn|social security|soc(?:ial)?\s*sec(?:urity)?|ss#)\b", re.I)
STATE_LABEL_RE = re.compile(r"^\s*state\b", re.I)
DATE_LABEL_RE  = re.compile(r"\b(date|dob|birth)\b", re.I)
INITIALS_RE    = re.compile(r"\binitials?\b", re.I)
WITNESS_RE     = re.compile(r"\bwitness\b", re.I)

IF_GUIDANCE_RE = re.compile(r"\b(if\s+(yes|no)[^)]*|if\s+so|if\s+applicable|explain below|please explain|please list)\b", re.I)

# Enhanced "If Yes" detection patterns (Fix 2)
IF_YES_FOLLOWUP_RE = re.compile(
    r'(.+?)\s*\[\s*\]\s*Yes\s*\[\s*\]\s*No\s+If\s+yes[,:]?\s*(?:please\s+)?explain',
    re.I
)
IF_YES_INLINE_RE = re.compile(
    r'(.+?)\s*\[\s*\]\s*Yes\s*\[\s*\]\s*No\s+If\s+yes',
    re.I
)

PAGE_NUM_RE = re.compile(r"^\s*(?:page\s*\d+(?:\s*/\s*\d+)?|\d+\s*/\s*\d+)\s*$", re.I)
ADDRESS_LIKE_RE = re.compile(
    r"\b(?:street|suite|ste\.?|ave|avenue|rd|road|blvd|zip|postal|fax|tel|phone|www\.|https?://|\.com|\.net|\.org|welcome|new\s+patients)\b",
    re.I,
)

# Enhanced header filtering patterns (Archivev8 Fix 2)
DENTAL_PRACTICE_EMAIL_RE = re.compile(
    r'@.*?(?:dental|dentistry|orthodontics|smiles).*?\.(com|net|org)',
    re.I
)
BUSINESS_WITH_ADDRESS_RE = re.compile(
    r'(?:dental|dentistry|orthodontics|family|cosmetic|implant).{20,}?(?:suite|ste\.?|ave|avenue|rd|road|st\.?|street)',
    re.I
)
PRACTICE_NAME_PATTERN = re.compile(
    r'^(?:.*?(?:dental|dentistry|orthodontics|family|cosmetic|implant).*?){1,3}$',
    re.I
)

INSURANCE_PRIMARY_RE   = re.compile(r"\bprimary\b.*\binsurance\b", re.I)
INSURANCE_SECONDARY_RE = re.compile(r"\bsecondary\b.*\binsurance\b", re.I)
INSURANCE_BLOCK_RE     = re.compile(r"(dental\s+benefit\s+plan|insurance\s+information|insurance\s+details)", re.I)

SINGLE_SELECT_TITLES_RE = re.compile(r"\b(marital\s+status|relationship|gender|sex)\b", re.I)

HEAR_ABOUT_RE   = re.compile(r"how\s+did\s+you\s+hear\s+about\s+us", re.I)
REFERRED_BY_RE  = re.compile(r"\b(referred\s+by|who\s+can\s+we\s+thank)\b", re.I)

RESP_PARTY_RE   = re.compile(r"responsible\s+party.*other\s+than\s+patient", re.I)
SINGLE_BOX_RE   = re.compile(r"^\s*\[\s*\]\s*(.+)$")

# broader Y/N capture (no boxes)
YN_SIMPLE_RE = re.compile(r"(?P<prompt>.*?)(?:\bYes\b|\bY\b)\s*(?:/|,|\s+)\s*(?:\bNo\b|\bN\b)", re.I)

# parent/guardian
PARENT_RE = re.compile(r"\b(parent|guardian|mother|father|legal\s+guardian)\b", re.I)

# Archivev12 Fix 2: Special field patterns for common fields without perfect formatting
# Phase 4 Fix 1: Enhanced patterns to detect checkbox-based Sex/Gender and Marital Status fields
SEX_GENDER_PATTERNS = [
    re.compile(r'\b(sex|gender)\s*[:\-]?\s*(?:M\s*or\s*F|M/F|Male/Female)', re.I),
    re.compile(r'\b(sex|gender)\s*\[\s*\]\s*(?:male|female|M|F)', re.I),
    # New: Match "Sex □ Male □ Female" pattern with checkbox characters
    re.compile(r'\bsex\s*' + CHECKBOX_ANY + r'\s*male\s*' + CHECKBOX_ANY + r'\s*female', re.I),
    re.compile(r'\bgender\s*' + CHECKBOX_ANY + r'\s*male\s*' + CHECKBOX_ANY + r'\s*female', re.I),
]

MARITAL_STATUS_PATTERNS = [
    re.compile(r'(?:please\s+)?circle\s+one\s*:?\s*(single|married|divorced|separated|widowed)', re.I),
    re.compile(r'\bmarital\s+status\s*:?\s*(?:\[\s*\]|single|married)', re.I),
    # New: Match "Marital Status □ Married □ Single..." pattern with checkboxes
    re.compile(r'\bmarital\s+status\s*' + CHECKBOX_ANY, re.I),
]

# Phase 4 Fix 3: Pattern for "Preferred method of contact" fields
PREFERRED_CONTACT_PATTERNS = [
    re.compile(r'(?:what\s+is\s+your\s+)?preferred\s+method\s+of\s+contact', re.I),
    re.compile(r'preferred\s+contact\s+method', re.I),
]

PHONE_PATTERNS = [
    (r'work\s+phone', 'work_phone'),
    (r'home\s+phone', 'home_phone'),
    (r'(?:cell|mobile)\s+phone', 'cell_phone'),
]

ALLOWED_TYPES = {"input", "date", "states", "radio", "dropdown", "terms", "signature"}

PRIMARY_SUFFIX = "__primary"
SECONDARY_SUFFIX = "__secondary"

# ---------- Debug/Reporting

@dataclass
class MatchEvent:
    title: str
    parsed_key: str
    section: str
    matched_key: Optional[str]
    reason: str
    score: float
    coverage: float

class DebugLogger:
    def __init__(self, enabled: bool):
        self.enabled = enabled
        self.events: List[MatchEvent] = []
        self.near_misses: List[MatchEvent] = []
        self.gates: List[str] = []

    def log(self, ev: MatchEvent):
        if self.enabled:
            self.events.append(ev)

    def log_near(self, ev: MatchEvent):
        if self.enabled:
            self.near_misses.append(ev)

    def gate(self, msg: str):
        if self.enabled:
            self.gates.append(msg)

    def print_summary(self):
        if not self.enabled:
            return
        print("  [debug] template matches:")
        for ev in self.events:
            print(f"    ✓ '{ev.title}' -> {ev.matched_key} ({ev.reason}, score={ev.score:.2f}, cov={ev.coverage:.2f})")
        if self.near_misses:
            print("  [debug] near-misses (score>=0.75 but rejected):")
            for ev in self.near_misses:
                print(f"    ~ '{ev.title}' -> {ev.matched_key or '—'} ({ev.reason}, score={ev.score:.2f}, cov={ev.coverage:.2f})")
        if self.gates:
            print("  [debug] gates:")
            for g in self.gates:
                print(f"    • {g}")

# ---------- Normalization helpers

SPELL_FIX = {
    "rregular": "Irregular",
    "hyploglycemia": "Hypoglycemia",
    "diabates": "Diabetes",
    "osteoperosis": "Osteoporosis",
    "artritis": "Arthritis",
    "rheurnatism": "Rheumatism",
    "e": "Email",
}

# Text preprocessing functions now imported from modules.text_preprocessing
# These functions handle line cleanup, normalization, and soft-wrap coalescing:
# - normalize_glyphs_line, collapse_spaced_letters_any, collapse_spaced_caps
# - read_text_file, is_heading, is_category_header, normalize_section_name
# - detect_repeated_lines, is_address_block, scrub_headers_footers, coalesce_soft_wraps

# ---------- Fix 1: Split Multi-Question Lines

def split_multi_question_line(line: str) -> List[str]:
    """
    Split lines containing multiple independent questions into separate lines.
    
    Example:
        Input:  "Gender: [ ] Male [ ] Female     Marital Status: [ ] Married [ ] Single"
        Output: ["Gender: [ ] Male [ ] Female", "Marital Status: [ ] Married [ ] Single"]
    
    Detection criteria:
    - Line contains 2+ question labels
    - Significant spacing (4+ spaces) separates the questions
    - Each segment should have checkboxes
    
    Returns:
        List of question strings (original line if no split needed)
    """
    # Strategy: Look for patterns like "...] ... 4+spaces ... Label:"
    # This finds where one question ends (with ]) and another begins (with Label:)
    
    # Pattern: closing bracket, some text/spaces, then 4+ spaces, then a label with colon
    split_pattern = r'\]\s+([^\[]{0,50}?)\s{4,}([A-Z][A-Za-z\s]+?):\s*\['
    matches = list(re.finditer(split_pattern, line))
    
    if not matches:
        # No clear split points found
        return [line]
    
    # Build segments by splitting at the match positions
    segments = []
    last_end = 0
    
    for match in matches:
        # The split point is right before the label (group 2)
        split_pos = match.start() + len(match.group(0)) - len(match.group(2)) - 1 - len(': [')
        
        # Add the segment from last_end to split_pos
        segment = line[last_end:split_pos].strip()
        if segment and re.search(CHECKBOX_ANY, segment):
            segments.append(segment)
        
        last_end = split_pos
    
    # Add the final segment
    final_segment = line[last_end:].strip()
    if final_segment and re.search(CHECKBOX_ANY, final_segment):
        segments.append(final_segment)
    
    # Return segments if we successfully split, otherwise original line
    return segments if len(segments) >= 2 else [line]


# ---------- Archivev12 Fix 1: Enhanced Multi-Field Line Splitting

# Known field labels dictionary for pattern matching
# Production Improvement: Use lookahead to handle underscores/dashes/punctuation after labels
# (?=[^a-zA-Z]|$) means "followed by non-letter or end of string"
KNOWN_FIELD_LABELS = {
    # Name fields
    'first_name': r'\bfirst\s+name(?=[^a-zA-Z]|$)',
    'last_name': r'\blast\s+name(?=[^a-zA-Z]|$)',
    'preferred_name': r'\bpreferred\s+name(?=[^a-zA-Z]|$)',
    'middle_initial': r'\b(?:middle\s+initial|m\.?i\.?)(?=[^a-zA-Z]|$)',
    'patient_name': r'\bpatient\s+name(?=[^a-zA-Z]|$)',
    'parent_name': r'\bparent\s+name(?=[^a-zA-Z]|$)',
    # Date/Age fields
    'birth_date': r'\b(?:birth\s+date|date\s+of\s+birth|birthdate)(?=[^a-zA-Z]|$)',
    'dob': r'\bdob(?=[^a-zA-Z]|$)',
    'age': r'\bage(?=[^a-zA-Z]|$)',
    'mother_dob': r"\bmother'?s?\s+dob(?=[^a-zA-Z]|$)",
    'father_dob': r"\bfather'?s?\s+dob(?=[^a-zA-Z]|$)",
    # Demographics
    'sex': r'\bsex(?=[^a-zA-Z]|$)',
    'gender': r'\bgender(?=[^a-zA-Z]|$)',
    'marital_status': r'\b(?:marital\s+status|please\s+circle\s+one)(?=[^a-zA-Z]|$)',
    # Contact fields
    'work_phone': r'\bwork\s+phone(?=[^a-zA-Z]|$)',
    'home_phone': r'\bhome\s+phone(?=[^a-zA-Z]|$)',
    'cell_phone': r'\b(?:cell|mobile)\s+phone(?=[^a-zA-Z]|$)',
    'parent_phone': r'\bparent\s+phone(?=[^a-zA-Z]|$)',
    'email': r'\be-?mail(?:\s+address)?(?=[^a-zA-Z]|$)',
    'emergency_contact': r'\bemergency\s+contact(?=[^a-zA-Z]|$)',
    'phone': r'\bphone(?=[^a-zA-Z]|$)',
    'ext': r'\bext\s*#?(?=[^a-zA-Z]|$)',
    'extension': r'\bextension(?=[^a-zA-Z]|$)',
    # Employment/Education
    'occupation': r'\boccupation(?=[^a-zA-Z]|$)',
    'employer': r'\b(?:employer|employed\s+by)(?=[^a-zA-Z]|$)',
    'parent_employer': r'\bparent\s+employer(?=[^a-zA-Z]|$)',
    'patient_employer': r'\bpatient\s+employed\s+by(?=[^a-zA-Z]|$)',
    'student': r'\b(?:full\s+time\s+)?student(?=[^a-zA-Z]|$)',
    # ID fields
    'ssn': r'\b(?:ssn|soc\.?\s*sec\.?|social\s+security)(?=[^a-zA-Z]|$)',
    'drivers_license': r'\bdrivers?\s+license\s*#?(?=[^a-zA-Z]|$)',
    'member_id': r'\bmember\s+id(?=[^a-zA-Z]|$)',
    'policy_holder': r'\bpolicy\s+holder(?=[^a-zA-Z]|$)',
    # Address fields
    'address': r'\b(?:mailing\s+)?address(?=[^a-zA-Z]|$)',
    'city': r'\bcity(?=[^a-zA-Z]|$)',
    'state': r'\bstate(?=[^a-zA-Z]|$)',
    'zip': r'\bzip(?:\s+code)?(?=[^a-zA-Z]|$)',
    'apt': r'\bapt\s*#?(?=[^a-zA-Z]|$)',
    # Insurance fields
    'group_number': r'\b(?:group\s*#|plan\s*/\s*group\s+number)(?=[^a-zA-Z]|$)',
    'local_number': r'\blocal\s*#(?=[^a-zA-Z]|$)',
    'insurance_company': r'\b(?:insurance\s+company|name\s+of\s+insurance)(?=[^a-zA-Z]|$)',
    'dental_plan_name': r'\bdental\s+plan\s+name(?=[^a-zA-Z]|$)',
    'plan_group_number': r'\bplan\s*/\s*group\s+number(?=[^a-zA-Z]|$)',
    'insured_name': r"\b(?:name\s+of\s+)?insured(?:'?s)?\s+name(?=[^a-zA-Z]|$)",
    'relationship_to_insured': r'\b(?:patient\s+)?relationship\s+to\s+insured(?=[^a-zA-Z]|$)',
    'id_number': r'\bid\s+number(?=[^a-zA-Z]|$)',
    # Misc
    'reason_for_visit': r'\breason\s+for\s+(?:today\'?s\s+)?visit(?=[^a-zA-Z]|$)',
    'previous_dentist': r'\bprevious\s+dentist(?=[^a-zA-Z]|$)',
}


def split_by_checkboxes_no_colon(line: str) -> List[str]:
    """
    Archivev12 Fix 1a: Split lines with checkboxes but no colons.
    Pattern: Label [ ] options ... Label [ ] options
    
    Strategy: Find field labels (capitalized words) that are followed by checkboxes,
    separated by 4+ spaces from the next field label.
    """
    # Find all potential field starts: Capital letter word followed by checkbox pattern
    # Look for pattern: 4+ spaces, then Capital letter starting a new field label
    # The key is to detect where one field ends and another begins by looking for spacing
    
    # Pattern to find split points: 4+ spaces followed by a capitalized label
    split_pattern = r'\s{4,}(?=[A-Z][A-Za-z\s]{2,30}?\s*\[)'
    
    split_positions = [m.start() for m in re.finditer(split_pattern, line)]
    
    if not split_positions:
        return [line]
    
    # Split at these positions
    segments = []
    last_pos = 0
    
    for pos in split_positions:
        segment = line[last_pos:pos].strip()
        if segment and re.search(CHECKBOX_ANY, segment):
            segments.append(segment)
        last_pos = pos
    
    # Add final segment
    final_segment = line[last_pos:].strip()
    if final_segment and re.search(CHECKBOX_ANY, final_segment):
        segments.append(final_segment)
    
    return segments if len(segments) >= 2 else [line]


def split_by_known_labels(line: str) -> List[str]:
    """
    Archivev12 Fix 1b + Production Improvement: Split lines based on known field labels.
    Handles: Work Phone (   )         Occupation
    Also handles: Are you a student? ... Mother's DOB ... Father's DOB
    NEW: Also handles adjacent labels with underscores (SSN_______ Date of Birth______)
    """
    # Find all known label matches in the line
    label_matches = []
    for field_key, pattern in KNOWN_FIELD_LABELS.items():
        for match in re.finditer(pattern, line, re.I):
            label_matches.append((match.start(), match.end(), field_key, match.group(0)))
    
    # Sort by position
    label_matches.sort()
    
    if len(label_matches) < 2:
        return [line]
    
    # Remove overlapping matches - keep the longer/more specific one
    filtered_matches = []
    for i, match in enumerate(label_matches):
        # Check if this match overlaps with any previous match
        overlaps = False
        for prev_match in filtered_matches:
            # Check if ranges overlap
            if not (match[1] <= prev_match[0] or match[0] >= prev_match[1]):
                # They overlap - keep the longer match
                overlaps = True
                break
        if not overlaps:
            filtered_matches.append(match)
    
    label_matches = filtered_matches
    
    if len(label_matches) < 2:
        return [line]
    
    # Production Improvement: Use more flexible splitting criteria
    segments = []
    last_added_idx = -1
    
    # If first label doesn't start at position 0, check for text before first big spacing gap
    # This handles cases like "Are you a student? Yes or No    Mother's DOB    Father's DOB"
    if label_matches[0][0] > 0:
        # Look for the first significant spacing gap (4+ spaces) before the second label
        if len(label_matches) >= 2:
            # Check text from start to second label
            text_before_second = line[:label_matches[1][0]]
            # Find position of first 4+ space gap
            gap_match = re.search(r'\s{4,}', text_before_second)
            if gap_match:
                # Extract everything before the gap as first segment
                before_gap = line[:gap_match.start()].strip()
                if before_gap and len(before_gap) > 5:
                    segments.append(before_gap)
    
    for i in range(len(label_matches)):
        start_pos = label_matches[i][0]
        
        if i + 1 < len(label_matches):
            # Check spacing between this label end and next label start
            end_this = label_matches[i][1]
            start_next = label_matches[i + 1][0]
            between = line[end_this:start_next]
            
            # Production Improvement: More flexible split criteria
            # Accept split if ANY of these conditions are met:
            # 1. 4+ consecutive spaces (original criterion)
            # 2. Underscores/dashes followed by 1+ space and the next label (e.g., "______ Date of Birth")
            # 3. Multiple underscores/dashes/slashes between labels (indicating separate input fields)
            has_wide_spacing = bool(re.search(r'\s{4,}', between))
            has_underscore_separator = bool(re.search(r'[_\-/]{3,}\s+', between))
            has_input_pattern = bool(re.search(r'[_\-]{3,}.*[_\-/()]{3,}', between))
            
            if not (has_wide_spacing or has_underscore_separator or has_input_pattern):
                continue
            
            # This is a valid split point
            end_pos = start_next
            segment = line[start_pos:end_pos].strip()
            if segment:
                segments.append(segment)
                last_added_idx = i
        else:
            # Last match - add from here to end
            segment = line[start_pos:].strip()
            if segment:
                segments.append(segment)
    
    # Only return segments if we got at least 2
    return segments if len(segments) >= 2 else [line]


def split_label_with_subfields(line: str) -> List[str]:
    """
    Archivev17 Fix: Handle pattern "Label: Sub1    Sub2    Sub3"
    
    Detects lines where a single label (ending with colon) is followed by multiple
    sub-labels separated by wide spacing (4+ spaces).
    
    Example: "Phone: Mobile                                  Home                                  Work"
    Should create: ["Phone: Mobile", "Phone: Home", "Phone: Work"]
    Or better: ["Mobile Phone", "Home Phone", "Work Phone"]
    """
    # Pattern: Label ending with colon, followed by multiple capitalized words separated by 4+ spaces
    # Must have at least 2 sub-labels to consider splitting
    match = re.match(r'^([A-Za-z][^:]{0,30}:)\s+([A-Z][a-z]+(?:\s{4,}[A-Z][a-z]+)+)\s*$', line.strip(), re.I)
    
    if not match:
        return [line]
    
    main_label = match.group(1).strip(':').strip()  # e.g., "Phone"
    sublabels_text = match.group(2)  # e.g., "Mobile    Home    Work"
    
    # Split by 4+ spaces to get individual sub-labels
    sublabels = [s.strip() for s in re.split(r'\s{4,}', sublabels_text) if s.strip()]
    
    # Must have at least 2 sub-labels to be valid
    if len(sublabels) < 2:
        return [line]
    
    # Create separate field entries
    # Format: "Sublabel Main-label" (e.g., "Mobile Phone", "Home Phone", "Work Phone")
    segments = []
    for sublabel in sublabels:
        # Create a natural-sounding field name
        if main_label.lower() in ['phone', 'number', 'address']:
            # For phone/number/address: "Mobile Phone", "Home Phone"
            segments.append(f"{sublabel} {main_label}")
        else:
            # For others: keep original format "Label: Sublabel"
            segments.append(f"{main_label}: {sublabel}")
    
    return segments if len(segments) >= 2 else [line]


def split_conditional_field_line(line: str) -> List[str]:
    """
    Archivev13 Fix: Handle conditional multi-field lines.
    Pattern: "Question? ... If condition: field1 ... field2"
    Example: "Are you a student? Yes or No If patient is a minor: Mother's DOB    Father's DOB"
    
    Note: Do NOT split yes/no questions with follow-up instructions like:
    "Are you taking medications? [ ] Yes [ ] No If yes, please explain:______"
    These should be handled by the compound yes/no logic instead.
    """
    # Look for "If ... :" pattern
    conditional_match = re.search(r'\b(if\s+[^:]{5,40}:)', line, re.I)
    if not conditional_match:
        return [line]
    
    # Check if this is a yes/no question with follow-up instructions
    # Pattern: checkbox or "Yes/No" before the "if" statement
    before_conditional = line[:conditional_match.start()]
    has_yesno_checkbox = bool(re.search(r'(?:yes|no|y|n)(?:\s*\[|\s*or\s)', before_conditional, re.I))
    
    # If it's "if yes" or "if no" followed by common follow-up keywords, don't split
    conditional_text = conditional_match.group(0).lower()
    is_followup_instruction = (
        ('if yes' in conditional_text or 'if no' in conditional_text) and
        any(keyword in conditional_text for keyword in ['explain', 'specify', 'list', 'describe', 'comment'])
    )
    
    if has_yesno_checkbox and is_followup_instruction:
        # This is a yes/no question with follow-up instructions, don't split
        return [line]
    
    conditional_text = conditional_match.group(0)
    conditional_start = conditional_match.start()
    
    # Split into:
    # 1. Text before conditional (should be a question)
    # 2. Text after conditional (contains multiple fields)
    before_conditional = line[:conditional_start].strip()
    after_conditional = line[conditional_match.end():].strip()
    
    segments = []
    
    # Add the question before conditional if it exists and is meaningful
    if before_conditional and len(before_conditional) > 5:
        segments.append(before_conditional)
    
    # Try to split the after_conditional part using known labels
    if after_conditional:
        after_segments = split_by_known_labels(after_conditional)
        if len(after_segments) > 1:
            segments.extend(after_segments)
        else:
            segments.append(after_conditional)
    
    return segments if len(segments) >= 2 else [line]


def split_compound_field_with_slashes(line: str) -> List[str]:
    """
    Enhancement 1: Split compound fields with slashes into separate fields.
    
    Examples:
        "Apt/Unit/Suite____" -> ["Apt", "Unit", "Suite"]
        "Name/Date/SSN____" -> ["Name", "Date", "SSN"]
        "Plan/Group Number____" -> ["Plan Number", "Group Number"]
    
    Only splits if:
    - Line contains field label(s) followed by slashes
    - Followed by underscores or other input markers (indicating it's a fillable field)
    - Each component is a reasonable field label (2+ characters)
    
    Returns:
        List of field segments (original line if no split needed)
    """
    # Pattern: One or more words/labels separated by slashes, followed by input markers
    # Example: "Apt/Unit/Suite________" or "Name/Date/SSN_______"
    pattern = r'^([A-Za-z][A-Za-z\s]*(?:/[A-Za-z][A-Za-z\s]*)+)\s*[:\-]?\s*([_\-\(\)]{3,})'
    match = re.match(pattern, line.strip())
    
    if not match:
        return [line]
    
    compound_label = match.group(1)
    input_marker = match.group(2)
    
    # Split by slash
    components = [c.strip() for c in compound_label.split('/') if c.strip()]
    
    # Only split if we have 2+ meaningful components
    if len(components) < 2:
        return [line]
    
    # Filter out single-letter components unless they're common abbreviations
    common_abbrevs = {'mi', 'm', 'f', 'n', 'y', 'apt', 'st', 'no'}
    valid_components = []
    for comp in components:
        # Keep if: 2+ chars, or is common abbreviation
        if len(comp) >= 2 or comp.lower() in common_abbrevs:
            valid_components.append(comp)
    
    if len(valid_components) < 2:
        return [line]
    
    # Create separate field lines
    segments = []
    for comp in valid_components:
        # Preserve some input markers for each field
        # Use proportional markers based on component count
        marker_len = max(3, len(input_marker) // len(valid_components))
        segments.append(f"{comp} {input_marker[:marker_len]}")
    
    return segments


def split_short_label_underscore_pattern(line: str) -> List[str]:
    """
    Category 1 Fix 1.1: Enhanced multi-field line splitting.
    
    Detects pattern: "Label1___ Label2___ Label3___" where labels are short words.
    Examples:
    - "First____ MI____ Last____"
    - "City____ State____ Zip____"
    - "Date____ Time____ Location____"
    
    This catches cases where the labels aren't in KNOWN_FIELD_LABELS.
    """
    # Pattern: Short word (2-15 chars, no spaces) followed by 3+ underscores
    # Must have at least 2 such patterns to be valid for splitting
    pattern = r'\b([A-Z][A-Za-z]{1,14})\s*_{3,}'
    matches = list(re.finditer(pattern, line))
    
    if len(matches) < 2:
        return [line]
    
    # Extract segments
    segments = []
    for i, match in enumerate(matches):
        if i + 1 < len(matches):
            # Extract from this label to the start of next label
            segment = line[match.start():matches[i+1].start()].strip()
            if segment:
                segments.append(segment)
        else:
            # Last segment - extract to end of line
            segment = line[match.start():].strip()
            if segment:
                segments.append(segment)
    
    # Only return segments if we successfully split into 2+ fields
    # and each segment has a reasonable length (not just underscores)
    if len(segments) >= 2 and all(len(s.strip('_').strip()) >= 2 for s in segments):
        return segments
    
    return [line]


def enhanced_split_multi_field_line(line: str) -> List[str]:
    """
    Archivev12 Fix 1 + Enhancement 1: Enhanced multi-field line splitting.
    Tries multiple strategies in order:
    0. Archivev15: Field label with inline checkbox (DON'T split these)
    1. Enhancement 1: Compound fields with slashes (Apt/Unit/Suite)
    2. Archivev17: Label with sub-fields (Phone: Mobile Home Work)
    3. Conditional field patterns (Archivev13)
    4. Existing pattern (colon + checkbox)
    5. Checkboxes without colons
    6. Known label patterns with spacing
    7. Category 1 Fix 1.1: Short label + underscore pattern (NEW)
    """
    # Archivev15 Fix 1: Check if this is a field with inline checkbox option
    # These should NOT be split, so return early
    if detect_field_with_inline_checkbox(line):
        return [line]
    
    # Enhancement 1: Try compound field splitting with slashes
    result = split_compound_field_with_slashes(line)
    if len(result) > 1:
        return result
    
    # Archivev17 Fix: Check if this is "Label: Sub1  Sub2  Sub3" pattern
    result = split_label_with_subfields(line)
    if len(result) > 1:
        return result
    
    # Try conditional field pattern first (Archivev13)
    result = split_conditional_field_line(line)
    if len(result) > 1:
        return result
    
    # Try existing pattern (backward compatible)
    result = split_multi_question_line(line)
    if len(result) > 1:
        return result
    
    # Try checkboxes without colons
    result = split_by_checkboxes_no_colon(line)
    if len(result) > 1:
        return result
    
    # Try known label detection
    result = split_by_known_labels(line)
    if len(result) > 1:
        return result
    
    # Category 1 Fix 1.1: Try short label + underscore pattern (NEW)
    result = split_short_label_underscore_pattern(line)
    if len(result) > 1:
        return result
    
    return [line]


def detect_sex_gender_field(line: str) -> Optional[Tuple[str, str]]:
    """
    Archivev12 Fix 2a: Detect sex/gender field patterns.
    Phase 4 Fix 1: Enhanced to handle checkbox patterns like "Sex □ Male □ Female"
    Returns: (field_type, segment) or None
    
    For lines with checkboxes (e.g., "Sex [ ] Male [ ] Female"), extract the entire field.
    For lines with text options (e.g., "Sex M or F"), extract up to the pattern.
    """
    for pattern in SEX_GENDER_PATTERNS:
        match = pattern.search(line)
        if match:
            # Check if this is a checkbox-based field
            # Look for checkboxes after the label
            after_label = line[match.end():]
            has_checkboxes = bool(re.search(CHECKBOX_ANY, after_label))
            
            if has_checkboxes or match.group(0).count('□') >= 2 or match.group(0).count('[') >= 2:
                # This is a checkbox-based field, extract the entire field including all checkboxes
                # Look for significant spacing (4+ spaces) followed by a capital letter (indicating next field)
                # OR look for "Marital Status" which commonly follows on same line
                next_field_match = re.search(r'\s{4,}[A-Z]', line[match.start():])
                if next_field_match:
                    # Extract up to next field
                    end_pos = match.start() + next_field_match.start()
                    return ("sex_gender", line[:end_pos].strip())
                else:
                    # No clear next field boundary, extract to end
                    # But check if line also contains "Marital Status" - if so, split there
                    marital_match = re.search(r'\bmarital\s+status', line[match.end():], re.I)
                    if marital_match:
                        # Extract up to "Marital Status"
                        end_pos = match.end() + marital_match.start()
                        return ("sex_gender", line[:end_pos].strip())
                    else:
                        return ("sex_gender", line.strip())
            else:
                # Text-based options (M or F), extract up to match end
                return ("sex_gender", line[:match.end()].strip())
    return None


def detect_marital_status_field(line: str) -> Optional[Tuple[str, str]]:
    """
    Archivev12 Fix 2b: Detect marital status field patterns.
    Phase 4 Fix 2: Enhanced to handle checkbox patterns
    Returns: (field_type, extracted_segment) or None
    """
    for pattern in MARITAL_STATUS_PATTERNS:
        match = pattern.search(line)
        if match:
            # For "Please Circle One:" pattern, need to capture options after it
            if "circle" in match.group(0).lower():
                # Extract from "Please Circle One:" onwards
                segment = line[match.start():].strip()
                return ("marital_status", segment)
            else:
                # For checkbox-based patterns, extract to end of line
                # (assume marital status is last field on line)
                segment = line[match.start():].strip()
                return ("marital_status", segment)
    return None


def detect_preferred_contact_field(line: str) -> Optional[Tuple[str, str]]:
    """
    Phase 4 Fix 3/8: Detect preferred method of contact field patterns.
    Returns: (field_type, extracted_segment) or None
    
    This field is typically a standalone line with a question followed by multiple checkbox options.
    Example: "What is your preferred method of contact? □ Mobile Phone □ Home Phone □ Work Phone □ E-mail"
    """
    for pattern in PREFERRED_CONTACT_PATTERNS:
        match = pattern.search(line)
        if match:
            # Extract the complete segment (question + all options)
            # Since this is typically a standalone field, extract entire line
            segment = line[match.start():].strip()
            
            # Verify we have multiple checkbox options (should have at least 2)
            checkbox_count = len(re.findall(CHECKBOX_ANY, segment))
            if checkbox_count >= 2:
                return ("preferred_contact", segment)
    return None


def split_complex_multi_field_line(line: str) -> List[str]:
    """
    Archivev12 Fix 2c: Handle complex lines with multiple fields of different types.
    E.g., "Sex M or F   Soc. Sec. #   Please Circle One: Single Married..."
    """
    segments = []
    remaining = line
    
    # Phase 4 Fix: Try to detect and extract preferred contact field first (it's usually a complete standalone line)
    pref_result = detect_preferred_contact_field(line)
    if pref_result:
        field_type, segment = pref_result
        segments.append(segment)
        return segments  # Preferred contact lines are typically standalone, return early
    
    # Try to detect and extract sex/gender field
    sex_result = detect_sex_gender_field(line)
    if sex_result:
        field_type, segment = sex_result
        segments.append(segment)
        # Remove this segment from remaining, accounting for position
        sex_pos = line.find(segment)
        if sex_pos == 0:
            remaining = line[len(segment):].strip()
        else:
            remaining = line[sex_pos + len(segment):].strip()
    
    # Try to detect and extract marital status field from remaining
    marital_result = detect_marital_status_field(remaining)
    if marital_result:
        field_type, segment = marital_result
        # Find the position of marital status segment in remaining
        marital_start = remaining.lower().find("please circle") if "please circle" in remaining.lower() else remaining.lower().find("marital")
        
        if marital_start > 0:
            # There's content before marital status (like SSN)
            before = remaining[:marital_start].strip()
            if before and len(before) > 3:  # Has significant content before
                segments.append(before)
        
        # Add the marital status field
        segments.append(segment)
        remaining = ""
    elif remaining:
        # If we extracted sex/gender, add remaining as separate field
        if segments and len(remaining) > 3:
            segments.append(remaining)
    
    return segments if len(segments) >= 2 else [line]


def preprocess_lines(lines: List[str]) -> List[str]:
    """
    Preprocess lines before main parsing.
    Currently handles: splitting multi-question lines with enhanced strategies.
    Enhancement: Recursively processes split segments to handle compound fields.
    """
    processed = []
    for line in lines:
        # Skip empty lines
        if not line.strip():
            processed.append(line)
            continue
        
        # Archivev12 Fix: Try multiple splitting strategies
        # Strategy 1: Check if line has sex/gender, marital, or preferred contact patterns
        has_sex_gender = any(p.search(line) for p in SEX_GENDER_PATTERNS)
        has_marital = any(p.search(line) for p in MARITAL_STATUS_PATTERNS)
        has_preferred_contact = any(p.search(line) for p in PREFERRED_CONTACT_PATTERNS)
        
        if has_sex_gender or has_marital or has_preferred_contact:
            # Try complex multi-field detection first for these special cases
            split_lines = split_complex_multi_field_line(line)
            if len(split_lines) == 1:
                # If complex didn't split, try enhanced
                split_lines = enhanced_split_multi_field_line(line)
        else:
            # Strategy 2: Enhanced multi-field splitting for regular cases
            split_lines = enhanced_split_multi_field_line(line)
        
        # Enhancement: Recursively process split segments
        # This catches compound fields like "Apt/Unit/Suite" that were created from splitting
        if len(split_lines) > 1:
            for segment in split_lines:
                # Try to split each segment further (e.g., compound fields with slashes)
                # But avoid infinite recursion by only trying compound splitting
                compound_split = split_compound_field_with_slashes(segment)
                processed.extend(compound_split)
        else:
            processed.extend(split_lines)
    
    return processed

# ---------- Options & typing

def extract_orphaned_checkboxes_and_labels(current_line: str, next_line: str) -> List[Tuple[str, Optional[bool]]]:
    """
    Fix 2: When current line has checkboxes but minimal text,
    and next line has label text, associate them by column position.
    
    Example:
      Current: "[ ]           [ ]           [ ]"
      Next:    "Anemia        Diabetes      Cancer"
      Returns: [("Anemia", None), ("Diabetes", None), ("Cancer", None)]
    """
    # Count checkboxes on current line
    checkbox_matches = list(re.finditer(CHECKBOX_ANY, current_line))
    if len(checkbox_matches) < 2:
        return []
    
    # Check if current line has minimal text (mostly just checkboxes)
    text_after_boxes = re.sub(CHECKBOX_ANY, '', current_line).strip()
    if len(text_after_boxes) > 50:  # Has substantial text, not orphaned
        return []
    
    # Check if next line has no checkboxes but has text
    if re.search(CHECKBOX_ANY, next_line):
        return []  # Next line also has checkboxes, not the label line
    
    next_stripped = next_line.strip()
    if not next_stripped or len(next_stripped) < 3:
        return []
    
    # Split next line into words/phrases by whitespace
    # Assume labels align roughly with checkbox positions
    words = re.split(r'\s{2,}', next_stripped)  # Split on 2+ spaces
    words = [w.strip() for w in words if w.strip()]
    
    # Match count: ideally num_words == num_checkboxes
    num_boxes = len(checkbox_matches)
    if len(words) < 2 or len(words) > num_boxes + 2:  # Some tolerance
        return []
    
    # Associate words with checkboxes
    options = []
    for word in words[:num_boxes]:  # Take up to num_boxes words
        if len(word) > 1:
            options.append((word, None))
    
    return options if len(options) >= 2 else []

def extract_title_from_inline_checkboxes(line: str) -> str:
    """
    Extract the question/prompt text before the first checkbox marker (Fix 1).
    
    Example:
        "How did you hear? [ ] Google [ ] Friend" -> "How did you hear?"
        "Gender: [ ] Male [ ] Female" -> "Gender:"
    """
    # Pattern to match text before first checkbox
    match = re.match(r'^(.*?)(?:\[\s*\]|\[x\]|☐|☑|□|■|❒|◻)', line)
    if match:
        title = match.group(1).strip()
        # Clean up trailing colons, question marks, etc
        title = title.rstrip(':? ').strip()
        if title:
            return title
    # Fallback: return cleaned line
    return re.sub(CHECKBOX_ANY, '', line).strip()

# clean_field_title moved to modules/question_parser.py (Patch 7 Phase 1)

# clean_token moved to modules/question_parser.py (Patch 7 Phase 1)

# normalize_opt_name moved to modules/question_parser.py (Patch 7 Phase 1)

def option_from_bullet_line(ln: str) -> Optional[Tuple[str, Optional[bool]]]:
    s = ln.strip()
    if not BULLET_RE.match(s):
        return None
    # Check if there are multiple checkboxes on this line (grid format, not bullet)
    checkbox_count = len(re.findall(CHECKBOX_ANY, s))
    if checkbox_count > 1:
        return None  # This is inline grid format, not a bullet
    s = CHECKBOX_MARK_RE.sub("", s, count=1)
    s = re.sub(r"^\s*[-*•·]\s+", "", s)
    name = clean_token(s)
    if not name:
        return None
    low = name.lower()
    if low in ("yes", "y"): return ("Yes", True)
    if low in ("no", "n"):  return ("No", False)
    return (name, None)

def detect_field_with_inline_checkbox(line: str) -> Optional[Tuple[str, str]]:
    """
    Archivev15 Fix 1: Detect lines with field label followed by inline checkbox option.
    
    Pattern: "Field Label:    <spaces>    [ ] Option text"
    
    Returns:
        Tuple of (field_label, checkbox_option) if pattern detected, None otherwise
    
    Examples:
        "Cell Phone:                         [ ] Yes, send me Text Message alerts"
        -> ("Cell Phone", "Yes, send me Text Message alerts")
        
        "E-mail Address:                     [ ] Yes, send me alerts via Email"
        -> ("E-mail Address", "Yes, send me alerts via Email")
    """
    # Look for pattern: text ending with colon, followed by spaces, then checkbox and text
    pattern = r'^(.+?):\s{5,}' + CHECKBOX_ANY + r'\s+(.+)$'
    match = re.match(pattern, line.strip())
    
    if match:
        field_label = match.group(1).strip()
        checkbox_text = match.group(2).strip()
        
        # Validate: field label should be reasonably short (not a question)
        # and checkbox text should be meaningful
        if len(field_label) <= 50 and len(checkbox_text) >= 5:
            return (field_label, checkbox_text)
    
    return None


def options_from_inline_line(ln: str) -> List[Tuple[str, Optional[bool]]]:
    """
    Enhanced to handle grid/multi-column layouts (Fix 1).
    Splits checkboxes that appear in columns with significant spacing.
    """
    s_norm = normalize_glyphs_line(ln)
    
    # First try: existing inline choice regex
    items: List[Tuple[str, Optional[bool]]] = []
    for m in INLINE_CHOICE_RE.finditer(s_norm):
        raw_label = m.group(1)
        
        # Fix 3: Split on excessive spacing BEFORE clean_token (which collapses spaces)
        parts = re.split(r'\s{5,}', raw_label)
        if len(parts) > 1:
            # Take only first part (the actual checkbox label)
            original = raw_label
            raw_label = next((p.strip() for p in parts if p.strip()), raw_label)
            # DEBUG
            if 'Bad Bite' in original and 'Please list' in original:
                import sys
                print(f"DEBUG: Split '{original[:60]}...' -> '{raw_label}'", file=sys.stderr)
        
        label = clean_token(raw_label)
        if not label: continue
        low = label.lower()
        if low in ("yes", "y"): items.append(("Yes", True))
        elif low in ("no", "n"): items.append(("No", False))
        else: items.append((label, None))
    
    # If we found options with existing method, use it (unless it looks like grid layout)
    if items and len(items) < 3:
        return items
    
    # NEW: Grid detection - look for multiple checkboxes with wide spacing (Fix 1)
    checkbox_positions = []
    for m in re.finditer(CHECKBOX_ANY, s_norm):
        checkbox_positions.append(m.start())
    
    if len(checkbox_positions) >= 3:  # Multiple checkboxes suggest grid
        # Split line into segments based on checkbox positions
        options = []
        for i, start_pos in enumerate(checkbox_positions):
            # Extract text after this checkbox until next checkbox or EOL
            if i + 1 < len(checkbox_positions):
                end_pos = checkbox_positions[i + 1]
            else:
                end_pos = len(s_norm)
            
            segment = s_norm[start_pos:end_pos]
            # Remove checkbox token and extract label
            label = re.sub(CHECKBOX_ANY, '', segment).strip()
            
            # Fix 3: Better cleaning for grid layouts
            # 1. Split on excessive spacing (5+ spaces = likely column boundary)
            parts = re.split(r'\s{5,}', label)
            if len(parts) > 1:
                # Take the first non-empty part (the actual label)
                label = next((p.strip() for p in parts if p.strip()), label)
            
            # 2. Split on category headers that appear mid-text (Fix 3 enhancement)
            # Pattern: text followed by category name followed by more text
            category_pattern = r'\b(Cardiovascular|Gastrointestinal|Neurological|Viral|Hematologic|Lymphatic|Infections?)\b'
            # Check if category appears in middle of text
            match = re.search(category_pattern, label, re.I)
            if match:
                # Split before the category and take the first part
                label = label[:match.start()].strip()
            
            # 3. Handle merged medical terms (Fix 3 - complex case)
            # Pattern: "Word1 Word2 (parenthetical) Word3" where Word3 looks unrelated
            # Example: "Artificial Angina (chest pain) Valve" should become "Artificial Heart Valve" or just "Artificial Valve"
            # If we have pattern like "X Y (...) Z" where Y and Z are both medical terms, keep only first part
            paren_match = re.search(r'^(.+?)\s+\w+\s*\([^)]+\)\s+(\w+)$', label)
            if paren_match:
                # This looks like merged terms. Try to clean it up.
                first_part = paren_match.group(1).strip()
                last_word = paren_match.group(2).strip()
                # If first part is short (1-2 words), combine with last word
                if len(first_part.split()) <= 2:
                    label = f"{first_part} {last_word}"
                else:
                    # Keep first part only
                    label = first_part
            
            # 4. Collapse remaining multiple spaces
            label = re.sub(r'\s{2,}', ' ', label)
            
            # 5. Remove trailing checkbox artifacts
            label = label.strip('[]')
            
            # 6. Filter out standalone category headers
            category_headers = r'^(Type|Cardiovascular|Gastrointestinal|Neurological|Viral|Women|Hematologic|Lymphatic|Infections?|Additional)$'
            if re.match(category_headers, label.strip(), re.I):
                continue
            
            # 7. Apply standard token cleaning
            label = clean_token(label)
            
            if label and len(label) > 1 and label.lower() not in YESNO_SET:
                options.append((label, None))
        
        if len(options) >= 2:  # Changed from >= 3 to be more permissive (Fix 3)
            return options
    
    return items  # Fall back to existing method

# classify_input_type moved to modules/question_parser.py (Patch 7 Phase 1)

# classify_date_input moved to modules/question_parser.py (Patch 7 Phase 1)

# ---------- Model

@dataclass
class Question:
    key: str
    title: str
    section: str
    type: str
    optional: bool = False
    control: Dict = field(default_factory=dict)
    conditional_on: Optional[List[Tuple[str, str]]] = None

# slugify moved to modules/question_parser.py (Patch 7 Phase 1)

# ---------- Archivev8 Fix 4: Clean Malformed Option Text

# clean_option_text moved to modules/question_parser.py (Patch 7 Phase 1)

# make_option moved to modules/question_parser.py (Patch 7 Phase 1)

# ---------- Composite / multi-label fan-out

CANON_LABELS = {
    "last name": "Last Name",
    "first name": "First Name",
    "mi": "MI",
    "middle initial": "MI",
    "nickname": "Preferred Name",
    "preferred name": "Preferred Name",
    "patient name": "Patient Name",
    "date of birth": "Date of Birth",
    "dob": "Date of Birth",
    "age": "Age",
    "address": "Address",
    "mailing address": "Address",
    "city": "City",
    "state": "State",
    "zip": "Zipcode",
    "zipcode": "Zipcode",
    "email": "Email",
    "e mail": "Email",
    "phone": "Phone",
    "home phone": "Home Phone",
    "mobile phone": "Mobile Phone",
    "cell phone": "Mobile Phone",
    "work phone": "Work Phone",
    "ssn": "SSN",
    "social security": "SSN",
    "soc sec": "SSN",
    "ss#": "SSN",
    "employer": "Employer",
    "employer (if different from above)": "Employer",
    "occupation": "Occupation",
    "emergency contact": "Emergency Contact",
    "emergency name": "Emergency Contact Name",
    "emergency phone": "Emergency Phone",
    "emergency relationship": "Emergency Relationship",
    "relationship": "Relationship",
    "person responsible for account": "Responsible Party Name",
    "responsible party name": "Responsible Party Name",
    "responsible party": "Responsible Party Name",
    "drivers license #": "Driver's License #",
    "driver's license #": "Driver's License #",
    "drivers license": "Driver's License #",
    "driver license": "Driver's License #",
    "name of parent": "Parent Name",
    "parent name": "Parent Name",
    "parent soc. sec. #": "Parent SSN",
    "parent ssn": "Parent SSN",
    # Insurance
    "insureds name": "Insured's Name",
    "insured name": "Insured's Name",
    "insureds": "Insured's Name",
    "insured": "Insured's Name",
    "subscriber name": "Insured's Name",
    "member name": "Insured's Name",
    "policy holder": "Insured's Name",
    "relationship to insured": "Relationship to Insured",
    "relationship to subscriber": "Relationship to Insured",
    "relationship to policy holder": "Relationship to Insured",
    "relationship to member": "Relationship to Insured",
    "id number": "ID Number",
    "id no": "ID Number",
    "member id": "ID Number",
    "policy id": "ID Number",
    "identification number": "ID Number",
    "group number": "Group Number",
    "group #": "Group Number",
    "grp #": "Group Number",
    "plan/group number": "Group Number",
    "insurance company": "Insurance Company",
    "insurance phone": "Insurance Phone",
    "insurance phone #": "Insurance Phone",
    "customer service phone": "Insurance Phone",
    "cust svc phone": "Insurance Phone",
    "address on card": "Insurance Address",
    "insurance address": "Insurance Address",
}

LABEL_ALTS = sorted(CANON_LABELS.keys(), key=len, reverse=True)

def _sanitize_words(s: str) -> str:
    s = s.lower()
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def try_split_known_labels(line: str) -> List[str]:
    s_raw = normalize_glyphs_line(line)
    s = collapse_spaced_caps(s_raw).strip()
    if not s or len(s) > 220 or s.endswith("."):
        return []
    # collapse repeated phrases like "Insured's Name Insured's Name"
    s_de_rep = re.sub(r"(\binsured'?s?\s+name\b)(\s+\1)+", r"\1", s, flags=re.I)
    s_sanit = _sanitize_words(s_de_rep)
    hits: List[Tuple[int, str]] = []
    for phrase in LABEL_ALTS:
        p = _sanitize_words(phrase)
        # Archivev20 Fix 9: Use word boundary matching to avoid false positives
        # "message alerts" was matching "age" and "ss", causing incorrect label extraction
        pattern = r'\b' + re.escape(p) + r'\b'
        match = re.search(pattern, s_sanit)
        if match:
            hits.append((match.start(), CANON_LABELS.get(phrase, phrase.title())))
    if len(hits) < 2:
        return []
    hits.sort(key=lambda t: t[0])
    labels = []
    for _pos, canon in hits:
        if canon not in labels:
            labels.append(canon)
    return labels


# Grid parsing functions now imported from modules.grid_parser
# These functions handle detection and parsing of multi-column checkbox grids:
# - looks_like_grid_header, detect_table_layout, parse_table_to_questions
# - chunk_by_columns, detect_column_boundaries
# - detect_multicolumn_checkbox_grid, parse_multicolumn_checkbox_grid
# - extract_text_for_checkbox, extract_text_only_items_at_columns

# ---------- Compound Yes/No

COMPOUND_YN_RE = re.compile(
    rf"(?P<prompt>[^[]*?)\s*{CHECKBOX_ANY}\s*(?:Yes|Y)\s*{CHECKBOX_ANY}\s*(?:No|N)\b",
    re.I,
)

def extract_compound_yn_prompts(line: str) -> List[str]:
    prompts = []
    for m in COMPOUND_YN_RE.finditer(normalize_glyphs_line(line)):
        p = collapse_spaced_caps(m.group("prompt")).strip(" :;-")
        if p:
            # Archivev19 Fix 2: Check if there's continuation text after the Yes/No checkboxes
            # Example: "...Actonel/ [ ] Yes [ ] No other medications containing bisphosphonates?"
            # We want to include the continuation text in the prompt
            match_end = m.end()
            remaining_text = line[match_end:].strip()
            
            # If there's text after Yes/No and it starts with lowercase or connecting words,
            # it's likely a continuation of the question
            if remaining_text and (
                re.match(r'^[a-z(]', remaining_text) or 
                re.match(r'^(and|or|if|but|then|with|of|for|to|other|additional)\b', remaining_text, re.I)
            ):
                # Remove any leading "and" or similar connectors that might cause awkwardness
                continuation = remaining_text
                # Append continuation to prompt
                p = p + " " + continuation
            
            prompts.append(p)
    if not prompts:
        m2 = YN_SIMPLE_RE.search(line)
        if m2:
            p = collapse_spaced_caps(m2.group("prompt")).strip(" :;-")
            if p: prompts.append(p)
    seen = set(); out=[]
    for p in prompts:
        if p not in seen:
            out.append(p); seen.add(p)
    return out

# ---------- Archivev8 Fix 1: Orphaned Checkbox Labels Detection

def has_orphaned_checkboxes(line: str) -> bool:
    """
    Detect if a line has multiple checkboxes but very little text (orphaned checkboxes).
    
    Example: "[ ]                       [ ]                               [ ]"
    
    Returns:
        True if checkboxes appear orphaned (labels likely on next line)
    """
    checkbox_count = len(re.findall(CHECKBOX_ANY, line))
    if checkbox_count < 2:
        return False
    
    # Remove checkboxes and see how much text remains
    text_without_checkboxes = re.sub(CHECKBOX_ANY, '', line).strip()
    
    # Split by whitespace to count words
    words = [w for w in text_without_checkboxes.split() if w.strip()]
    
    # Heuristic: If we have many checkboxes but very few words, labels are likely orphaned
    # Allow 1-2 short words per checkbox (like "Sickle Cell Disease" at the end)
    # But if most checkboxes have no adjacent text, they're orphaned
    if checkbox_count >= 3 and len(words) <= 2:
        return True
    
    # Alternative check: very sparse text density
    if len(text_without_checkboxes) < (checkbox_count * 5):
        return True
    
    return False


def extract_orphaned_labels(label_line: str) -> List[str]:
    """
    Extract labels from a line that appears to contain orphaned labels.
    
    A label line may have some checkboxes at the end, but should have
    labels without checkboxes at the beginning/middle.
    
    Returns:
        List of label strings
    """
    stripped = label_line.strip()
    if not stripped:
        return []
    
    # Split by 3+ spaces to get individual labels
    # This is a common pattern in grid layouts
    parts = re.split(r'\s{3,}', stripped)
    
    # Clean and filter labels
    cleaned_labels = []
    for part in parts:
        part = part.strip()
        # Skip if this part starts with a checkbox (it's properly paired)
        if re.match(CHECKBOX_ANY, part):
            # This part has a checkbox, extract the label after it
            label = re.sub(CHECKBOX_ANY, '', part).strip()
            if label and len(label) >= 2 and not label.isdigit():
                cleaned_labels.append(label)
        else:
            # This part has no checkbox - it's an orphaned label
            if len(part) >= 2 and not part.isdigit():
                cleaned_labels.append(part)
    
    return cleaned_labels


def associate_orphaned_labels_with_checkboxes(
    checkbox_line: str,
    label_line: str
) -> List[Tuple[str, Optional[bool]]]:
    """
    Associate orphaned labels with checkboxes based on occurrence order.
    
    Args:
        checkbox_line: Line with checkboxes but minimal text
        label_line: Next line with labels (may have some checkboxes at end)
    
    Returns:
        List of (label, checked_state) tuples
    """
    # Check if this actually looks like orphaned pattern
    if not has_orphaned_checkboxes(checkbox_line):
        return []
    
    labels = extract_orphaned_labels(label_line)
    if not labels:
        return []
    
    # Count checkboxes in the checkbox line
    checkbox_matches = list(re.finditer(CHECKBOX_ANY, checkbox_line))
    num_checkboxes = len(checkbox_matches)
    
    if num_checkboxes == 0:
        return []
    
    # Also check if checkbox line has any labels at the end
    # e.g., "[ ]  [ ]  [ ]  [ ]  [ ] Sickle Cell Disease"
    text_after_last_checkbox = checkbox_line[checkbox_matches[-1].end():].strip()
    checkbox_line_labels = []
    if text_after_last_checkbox and len(text_after_last_checkbox) > 3:
        # There's a label on the checkbox line itself
        checkbox_line_labels.append(text_after_last_checkbox)
    
    # If we have orphaned labels and checkboxes, associate them
    options = []
    
    # Add all labels from the label line
    for label in labels:
        options.append((label, None))
    
    # Then add any label from the checkbox line itself
    for label in checkbox_line_labels:
        options.append((label, None))
    
    return options

# ---------- Fix 2: Enhanced "If Yes" Detection

def extract_yn_with_followup(line: str) -> Tuple[Optional[str], bool]:
    """
    Extract Yes/No question and determine if it has a follow-up.
    
    Returns:
        (question_text, has_followup)
    
    Examples:
        "Are you pregnant? [ ] Yes [ ] No If yes, please explain"
        -> ("Are you pregnant?", True)
        
        "Do you smoke? [ ] Yes [ ] No"
        -> ("Do you smoke?", False)
    """
    # Try explicit "if yes" pattern first
    match = IF_YES_FOLLOWUP_RE.search(line)
    if match:
        question = match.group(1).strip()
        return (question, True)
    
    # Try inline "if yes" pattern
    match = IF_YES_INLINE_RE.search(line)
    if match:
        question = match.group(1).strip()
        return (question, True)
    
    # Try existing compound pattern
    prompts = extract_compound_yn_prompts(line)
    if prompts:
        # Check if line mentions "if yes" anywhere
        has_followup = bool(re.search(r'\bif\s+yes\b', line, re.I))
        return (prompts[0], has_followup)
    
    return (None, False)


def create_yn_question_with_followup(
    question_text: str,
    section: str,
    key_base: Optional[str] = None
) -> List['Question']:
    """
    Create a Yes/No radio question with a conditional follow-up input field.
    
    Args:
        question_text: The question text
        section: Current section
        key_base: Base key (if None, generated from question_text)
    
    Returns:
        List of 2 Questions: [radio_question, followup_input]
    """
    if not key_base:
        key_base = slugify(question_text)
    
    # Main Yes/No question
    main_q = Question(
        key_base,
        question_text,
        section,
        "radio",
        control={"options": [make_option("Yes", True), make_option("No", False)]}
    )
    
    # Follow-up input field (conditional on Yes)
    followup_key = f"{key_base}_explanation"
    followup_q = Question(
        followup_key,
        "Please explain",
        section,
        "input",
        control={"input_type": "text", "hint": "Please provide details"}
    )
    followup_q.conditional_on = [(key_base, "yes")]
    
    return [main_q, followup_q]


# Template matching functions now imported from modules.template_catalog
# These functions handle field standardization against the template dictionary:
# - TemplateCatalog class for loading and matching templates
# - FindResult dataclass for match results
# - merge_with_template for merging parsed fields with templates
# - Helper functions for text normalization and matching

# ---------- Parsing

def _emit_parent_guardian_override(title: str, key: str, qtype: str, ctrl: Dict, section: str, insurance_scope: Optional[str], debug: bool):
    """Route parent/guardian-labeled fields to parent_* keys when appropriate."""
    if not PARENT_RE.search(title):
        return key, qtype, ctrl
    low = title.lower()
    if SSN_RE.search(low):
        if debug: print(f"  [debug] gate: parent_routing -> '{title}' -> parent_ssn")
        return "parent_ssn", "input", {"input_type":"ssn"}
    if PHONE_RE.search(low):
        if debug: print(f"  [debug] gate: parent_routing -> '{title}' -> parent_phone")
        return "parent_phone", "input", {"input_type":"phone"}
    if re.search(r"\b(name)\b", low):
        if debug: print(f"  [debug] gate: parent_routing -> '{title}' -> parent_name")
        return "parent_name", "input", {"input_type":"text"}
    return key, qtype, ctrl

def _insurance_scope_key(key: str, section: str, insurance_scope: Optional[str], title: str, debug: bool) -> str:
    """Attach __primary/__secondary to SSN/ID under insurance context; prefer patient-level elsewhere."""
    low = title.lower()
    if "insurance" in section.lower() or insurance_scope or re.search(r"\b(insured|subscriber|policy|member)\b", low):
        if key == "ssn" and insurance_scope:
            if debug: print(f"  [debug] gate: ssn_scoped -> '{title}' -> ssn{insurance_scope}")
            return f"ssn{insurance_scope}"
    return key

def _insurance_id_ssn_fanout(title: str) -> Optional[List[Tuple[str, str, Dict]]]:
    """Detect lines that contain both ID and SS tokens and fan-out to two controls."""
    t = _sanitize_words(title)
    has_id = bool(re.search(r"\b(id|member\s*id|policy\s*id|identification\s*number|subscriber\s*id|policy\s*#|member\s*#)\b", t))
    has_ss = bool(re.search(r"\b(ssn|social\s*security|ss#|soc\s*sec)\b", t))
    if has_id and has_ss:
        return [("insurance_id_number", "input", {"input_type":"text"}), ("ssn", "input", {"input_type":"ssn"})]
    return None


def detect_fill_in_blank_field(line: str, prev_line: Optional[str] = None) -> Optional[Tuple[str, str]]:
    """
    Category 1 Fix 1.2: Detect standalone fill-in-blank fields.
    
    Pattern: Lines with mostly underscores (5+ consecutive underscores).
    Uses text on same line or previous line as label.
    
    Returns: (key, title) or None
    """
    # Check if line has 5+ consecutive underscores
    if not re.search(r'_{5,}', line):
        return None
    
    # IMPORTANT: If line has multiple underscore groups with text between them,
    # it's likely a multi-field line that should be handled by other splitters
    # Pattern: text___ text___ indicates multiple fields, not a single fill-in-blank
    underscore_groups = re.findall(r'_{5,}', line)
    if len(underscore_groups) > 1:
        # Check if there's meaningful text between the underscore groups
        # Split by underscores and check text chunks
        parts = re.split(r'_{5,}', line)
        text_chunks_between = [p.strip() for p in parts[1:-1] if p.strip()]  # Middle chunks
        # If there are text labels between underscore groups, this is multi-field
        if text_chunks_between and any(len(c) > 2 for c in text_chunks_between):
            return None  # Let multi-field splitters handle this
    
    # Count underscore vs non-underscore content
    underscore_count = line.count('_')
    non_underscore_chars = len([c for c in line if c not in ('_', ' ', '\t')])
    
    # If line is mostly underscores (2:1 ratio), it's a fill-in-blank
    if underscore_count < 5 or underscore_count < non_underscore_chars * 2:
        return None
    
    # Try to extract label from same line (before underscores)
    label_match = re.match(r'^([^_]+?)[:.]?\s*_{5,}', line)
    if label_match:
        label = label_match.group(1).strip()
        if label and len(label) >= 2:
            return (slugify(label), label)
    
    # Try to use previous line as label if available
    if prev_line:
        prev_clean = prev_line.strip().rstrip(':.')
        if prev_clean and len(prev_clean) < 100 and not re.search(CHECKBOX_ANY, prev_clean):
            # Make sure it's not a heading or instructional text
            if not is_heading(prev_clean):
                # Archivev22 Enhancement: Don't use long descriptive sentences as labels for underscores
                # If the previous line is very long or looks like a sentence, skip it
                if len(prev_clean) < 80 and not (prev_clean.endswith('.') and len(prev_clean) > 50):
                    return (slugify(prev_clean), prev_clean)
    
    # Archivev22 Enhancement: Don't create generic placeholders for orphaned underscores
    # These are often signature lines or date lines without clear context
    # Only create them if the line has some identifying text
    line_text = re.sub(r'_{5,}', '', line).strip()
    if line_text and len(line_text) >= 2:
        # Has some text, create generic with that text
        return (slugify(line_text), line_text)
    
    # No label found and no identifying text - skip this underscore field
    return None


def detect_inline_checkbox_with_text(line: str) -> Optional[Tuple[str, str, str]]:
    """
    Detect inline checkboxes with continuation text.
    
    Example: "[ ] Yes, send me text alerts"
    Returns: ("yes_text_alerts", "Yes, send me text alerts", "radio")
    
    Priority 2.3: Inline Checkbox with Continuation Text
    - Detects checkboxes embedded mid-sentence
    - Extracts the boolean option and the continuation text
    - Pattern: "[ ] Yes/No, [descriptive text]"
    """
    # Archivev21 Fix 6: Make pattern more strict to avoid false positives
    # Require comma or "send" after Yes/No to ensure it's a continuation, not a separate field
    # Pattern: checkbox followed by Yes/No, then comma/space and continuation text
    pattern = r'^\s*' + CHECKBOX_ANY + r'\s*(Yes|No)[\s,]+(.*?)$'
    match = re.match(pattern, line, re.I)
    
    if not match:
        return None
    
    option = match.group(1).capitalize()  # "Yes" or "No"
    continuation = match.group(2).strip()
    
    # Need meaningful continuation text (at least 10 chars)
    # Archivev21 Fix 6: Also check that continuation doesn't look like a standalone field label
    # (i.e., doesn't start with a capital letter followed by lowercase and end with "Insurance", "Plan", etc.)
    if len(continuation) < 10:
        return None
    
    # Check if this looks like a false positive (e.g., "[ ] N o D ental Insurance")
    # If continuation starts with lowercase or has spaces between capital letters, likely OCR error
    if re.match(r'^[a-z]\s+[A-Z]', continuation):
        return None  # Likely "N o D ental" pattern - not a real continuation
    
    # Archivev21 Fix 6: Clean continuation text to fix any remaining OCR errors
    continuation_cleaned = clean_field_title(continuation)
    
    # Generate a descriptive key from the cleaned continuation
    key = slugify(continuation_cleaned)
    if len(key) > 40:
        key = key[:40]
    
    # Title includes both the option and the cleaned description
    title = f"{option}, {continuation_cleaned}"
    
    # Determine field type - usually a boolean/radio
    field_type = "radio"
    
    return (key, title, field_type)


def detect_multi_field_line(line: str) -> Optional[List[Tuple[str, str]]]:
    """
    Detect lines with a single label followed by multiple blank fields.
    
    Example: "Phone: Mobile _____ Home _____ Work _____"
    Returns: [("phone_mobile", "Mobile"), ("phone_home", "Home"), ("phone_work", "Work")]
    
    Priority 2.1: Multi-Field Label Splitting
    - Detects multiple underscores or blanks after a single label
    - Identifies common sub-field keywords (Home/Work/Cell, Mobile/Office, Primary/Secondary)
    - Uses spacing analysis to detect distinct blank columns
    """
    # Pattern: Label: followed by multiple keywords with blanks/underscores
    # Common keywords for sub-fields
    sub_field_keywords = {
        'mobile': 'mobile',
        'cell': 'mobile',
        'home': 'home',
        'work': 'work',
        'office': 'work',
        'primary': 'primary',
        'secondary': 'secondary',
        'personal': 'personal',
        'business': 'business',
        'other': 'other',
        'fax': 'fax',
        'preferred': 'preferred',
        # Patch 2: Add time-of-day keywords for phone fields
        'day': 'day',
        'evening': 'evening',
        'night': 'night',
        # Archivev21 Fix 3: Add common name field keywords
        'first': 'first',
        'last': 'last',
        'middle': 'middle',
        'mi': 'middle_initial',
        'nickname': 'nickname',
        'preferred': 'preferred',
    }
    
    # Look for a label (word/phrase ending with colon) followed by multiple sub-fields
    # Pattern: "Label: Keyword1 ____ Keyword2 ____ Keyword3 ____"
    label_match = re.match(r'^([A-Za-z\s]+?):\s+(.+)$', line)
    if not label_match:
        return None
    
    base_label = label_match.group(1).strip()
    remainder = label_match.group(2)
    
    # Patch 2: Normalize slashes to spaces (e.g., "Day/Evening" -> "Day Evening")
    remainder = re.sub(r'/', ' ', remainder)
    
    # Look for multiple keywords separated by blanks/underscores
    # Pattern: keyword followed by blanks/underscores (at least 2)
    blank_pattern = r'[_\s]{2,}'
    
    # Split by significant blank sequences
    parts = re.split(blank_pattern, remainder)
    
    # Filter to get only meaningful keywords
    keywords_found = []
    for part in parts:
        part = part.strip()
        if not part:
            continue
        # Check if this part is a known sub-field keyword
        part_lower = part.lower()
        if part_lower in sub_field_keywords:
            keywords_found.append((part, sub_field_keywords[part_lower]))
    
    # Need at least 2 keywords to be a multi-field line
    if len(keywords_found) < 2:
        return None
    
    # Generate field descriptors
    base_key = slugify(base_label)
    result = []
    for display_name, suffix_key in keywords_found:
        field_key = f"{base_key}_{suffix_key}"
        # Archivev21 Fix 3: For name fields, use simpler titles
        if base_label.lower() in ['patient name', 'name', 'insured name', "insured's name"]:
            # Use just the subfield name as title (e.g., "First Name", "Last Name")
            field_title = f"{display_name.title()} Name" if display_name.lower() in ['first', 'last', 'middle'] else display_name.title()
        else:
            field_title = f"{base_label} ({display_name})"
        result.append((field_key, field_title))
    
    return result


def detect_inline_text_options(line: str) -> Optional[Tuple[str, str, List[Tuple[str, str]]]]:
    """
    Enhancement 2: Detect questions with inline text options.
    
    Patterns to detect:
    - "Question? Y or N" -> Yes/No options
    - "Question? Yes or No" -> Yes/No options
    - "Sex M or F" -> Male/Female options
    - "Gender: Male/Female" -> Male/Female options
    
    Returns:
        Tuple of (question_text, option_type, options) where options is [(name, value), ...]
        None if no inline options detected
    """
    line_stripped = line.strip()
    
    # Pattern 1: Y or N (with optional question mark and "If yes/no" continuation)
    yn_pattern = r'^(.+?)\s+([Yy]\s+or\s+[Nn])\s*(?:,?\s*[Ii]f\s+(?:yes|no).*)?$'
    yn_match = re.match(yn_pattern, line_stripped)
    if yn_match:
        question_text = yn_match.group(1)
        # Clean up the question text
        question_text = re.sub(r'\s+$', '', question_text)
        
        options = [
            ("Yes", "yes"),
            ("No", "no")
        ]
        return (question_text, "yes_no", options)
    
    # Pattern 2: Yes or No (full words)
    yesno_pattern = r'^(.+?)\s+(Yes\s+or\s+No)\s*(?:,?\s*[Ii]f\s+(?:yes|no).*)?$'
    yesno_match = re.match(yesno_pattern, line_stripped, re.I)
    if yesno_match:
        question_text = yesno_match.group(1)
        question_text = re.sub(r'\s+$', '', question_text)
        
        options = [
            ("Yes", "yes"),
            ("No", "no")
        ]
        return (question_text, "yes_no", options)
    
    # Pattern 3: M or F / Male or Female (Sex/Gender)
    sex_pattern = r'^(.+?)\s+(?:M\s+or\s+F|Male\s+or\s+Female|M/F|Male/Female)\s*'
    sex_match = re.match(sex_pattern, line_stripped, re.I)
    if sex_match:
        question_text = sex_match.group(1)
        # If question text is just "Sex" or "Gender", that's the label
        question_text = re.sub(r'[:\-]?\s*$', '', question_text)
        
        options = [
            ("Male", "male"),
            ("Female", "female"),
            ("Other", "other"),
            ("Prefer not to self identify", "not_say")
        ]
        return (question_text, "sex_gender", options)
    
    # Category 1 Fix 1.3: Pattern 4 - "Circle one:" or "Check one:" followed by space-separated options
    circle_pattern = r'^(.+?)(?:circle|check)\s+one:\s*(.+)$'
    circle_match = re.match(circle_pattern, line_stripped, re.I)
    if circle_match:
        question_text = circle_match.group(1).strip()
        options_text = circle_match.group(2).strip()
        
        # Split options by whitespace (2+ spaces) or common separators
        option_list = re.split(r'\s{2,}|,\s*|\|\s*', options_text)
        options = []
        for opt in option_list:
            opt = opt.strip()
            if opt and len(opt) > 1:  # Skip single chars
                # Create value from option text
                opt_value = opt.lower().replace(' ', '_').replace('-', '_')
                options.append((opt, opt_value))
        
        # Need at least 2 options
        if len(options) >= 2:
            # If question text is empty, use "Please select one"
            if not question_text:
                question_text = "Please select one"
            return (question_text, "select_one", options)
    
    # Category 1 Fix 1.3: Pattern 5 - Options separated by slashes without checkbox markers
    # e.g., "Marital Status: Single/Married/Divorced"
    slash_options_pattern = r'^(.+?):\s*([A-Za-z]+(?:/[A-Za-z]+){1,})\s*$'
    slash_match = re.match(slash_options_pattern, line_stripped)
    if slash_match:
        question_text = slash_match.group(1).strip()
        options_text = slash_match.group(2)
        
        # Split by slashes
        option_list = options_text.split('/')
        options = []
        for opt in option_list:
            opt = opt.strip()
            if opt:
                opt_value = opt.lower().replace(' ', '_')
                options.append((opt, opt_value))
        
        # Need at least 2 options and all options should be short (single words/phrases)
        if len(options) >= 2 and all(len(o[0]) < 20 for o in options):
            return (question_text, "select_one", options)
    
    return None


def parse_to_questions(text: str, debug: bool=False) -> List[Question]:
    lines = [normalize_glyphs_line(x) for x in scrub_headers_footers(text)]
    lines = coalesce_soft_wraps(lines)
    
    # Fix 1: Preprocess to split multi-question lines
    lines = preprocess_lines(lines)

    questions: List[Question] = []
    cur_section = "General"
    seen_signature = False
    insurance_scope: Optional[str] = None  # "__primary" / "__secondary"

    i = 0
    while i < len(lines):
        raw = lines[i]
        line = collapse_spaced_caps(raw.strip())
        
        # Debug specific lines
        if debug and 'Appearance' in raw and 'Function' in raw:
            print(f"  [debug] PROCESSING line {i}: '{raw[:80]}' (section={cur_section})")
        
        if not line:
            i += 1; continue

        # Insurance anchoring
        if INSURANCE_BLOCK_RE.search(line):
            cur_section = "Insurance"; insurance_scope = None
        if INSURANCE_PRIMARY_RE.search(line):
            cur_section = "Insurance"; insurance_scope = "__primary"
        if INSURANCE_SECONDARY_RE.search(line):
            cur_section = "Insurance"; insurance_scope = "__secondary"

        # Archivev12 Fix: Check for special field patterns BEFORE heading detection
        # to prevent them from being treated as headings
        # Phase 4 Fix: Also check for preferred contact patterns
        is_special_sex_field = any(p.search(line) for p in SEX_GENDER_PATTERNS)
        is_special_marital_field = any(p.search(line) for p in MARITAL_STATUS_PATTERNS)
        is_special_preferred_contact = any(p.search(line) for p in PREFERRED_CONTACT_PATTERNS)
        is_special_field = is_special_sex_field or is_special_marital_field or is_special_preferred_contact
        
        # Fix 2: Section heading with multi-line header detection
        if not is_special_field and is_heading(line):
            # Look ahead to see if the next line is also a heading (multi-line header)
            potential_headers = [line]
            j = i + 1
            while j < len(lines) and j < i + 3:  # Look ahead up to 2 lines
                next_raw = lines[j]
                next_line = collapse_spaced_caps(next_raw.strip())
                if not next_line:
                    break
                # Archivev12 Fix: Don't include special fields in multi-line headers
                is_next_special_sex = any(p.search(next_line) for p in SEX_GENDER_PATTERNS)
                is_next_special_marital = any(p.search(next_line) for p in MARITAL_STATUS_PATTERNS)
                is_next_special = is_next_special_sex or is_next_special_marital
                
                if is_heading(next_line) and not is_next_special:
                    potential_headers.append(next_line)
                    j += 1
                else:
                    break
            
            # If we found multiple consecutive headings, combine them
            if len(potential_headers) > 1:
                combined = " ".join(potential_headers)
                new_section = normalize_section_name(combined)
                cur_section = new_section
                if debug:
                    print(f"  [debug] multi-line header: {potential_headers} -> {cur_section}")
                i = j  # Skip past all the header lines
                continue
            else:
                new_section = normalize_section_name(line)
                # Archivev10 Fix: Don't override Medical/Dental History sections with "General"
                # This prevents random headings within those sections from changing the section
                # But DO allow changing between specific sections
                if cur_section in {"Medical History", "Dental History"} and new_section == "General":
                    # Keep the current specific section, don't change to General
                    pass
                else:
                    cur_section = new_section
            
            low = line.lower()
            if "insurance" in low:
                if "primary" in low: insurance_scope = "__primary"
                elif "secondary" in low: insurance_scope = "__secondary"
                else: insurance_scope = None
            else:
                insurance_scope = None
            i += 1; continue
        
        # Archivev10 Fix 2: Enhanced category header detection
        # Check if this is a category header that precedes a multi-column grid
        if i + 1 < len(lines):
            next_line = lines[i + 1]
            is_cat_header = is_category_header(line, next_line)
            if debug and is_cat_header:
                print(f"  [debug] is_category_header=True for line {i}: '{line[:60]}' (section={cur_section})")
            if is_cat_header:
                # Before skipping, check if this is actually a multi-column grid header
                # (e.g., "Appearance    Function    Habits")
                if cur_section in {"Medical History", "Dental History"}:
                    # Check if line has multiple column-like parts and next line has multiple checkboxes
                    parts = re.split(r'\s{5,}', line.strip())
                    next_checkboxes = len(list(re.finditer(CHECKBOX_ANY, next_line)))
                    
                    if debug:
                        print(f"  [debug] category header check: '{line[:60]}' - parts={len(parts)}, next_cb={next_checkboxes}")
                    
                    if len(parts) >= 3 and next_checkboxes >= 3:
                        # This is a multi-column grid header! Try to detect and parse the grid
                        if debug:
                            print(f"  [debug] attempting multicolumn_grid detection from category header line {i}")
                        multicolumn_grid = detect_multicolumn_checkbox_grid(lines, i, cur_section)
                        if multicolumn_grid:
                            grid_question = parse_multicolumn_checkbox_grid(lines, multicolumn_grid, debug)
                            if grid_question:
                                questions.append(grid_question)
                                i = max(multicolumn_grid['data_lines']) + 1
                                continue
                        elif debug:
                            print(f"  [debug] multicolumn_grid detection failed")
                
                # If not a grid header, skip as before
                if debug:
                    print(f"  [debug] skipping category header: '{line[:60]}'")
                i += 1
                continue

        # Archivev8 Fix 1: Check for orphaned checkbox pattern
        # Use raw line (not collapsed) to preserve spacing
        if has_orphaned_checkboxes(raw) and i + 1 < len(lines):
            next_line = lines[i + 1]
            orphaned_options = associate_orphaned_labels_with_checkboxes(raw, next_line)
            
            if orphaned_options and len(orphaned_options) >= 2:
                # Found orphaned labels! Create a medical conditions question
                # Look back for a title
                title = None
                if i > 0 and len(lines[i-1].strip()) < 100:
                    prev_stripped = collapse_spaced_caps(lines[i-1].strip())
                    if prev_stripped and not re.search(CHECKBOX_ANY, prev_stripped):
                        title = prev_stripped.rstrip(':?.')
                
                if not title:
                    title = "Medical Conditions"
                
                key = slugify(title)
                q = Question(
                    key,
                    title,
                    cur_section,
                    "dropdown",
                    control={"options": [make_option(name, checked) for name, checked in orphaned_options], "multi": True}
                )
                questions.append(q)
                
                if debug:
                    print(f"  [debug] gate: orphaned_labels -> '{title}' with {len(orphaned_options)} options")
                
                # Skip the next line since we consumed it
                i += 2
                continue

        # --- NEW: Medical History Multi-select block ---
        if cur_section in {"Medical History", "Dental History"}:
            if re.search(r"\b(have you ever had|do you have|are you taking)\b", line, re.I) and not extract_compound_yn_prompts(line):
                main_prompt_title = line
                options: List[Tuple[str, Optional[bool]]] = []
                k = i + 1
                while k < len(lines) and lines[k].strip() and not is_heading(lines[k]):
                    option_line = lines[k]
                    
                    # Fix 3: Skip category headers within medical blocks
                    if k + 1 < len(lines) and is_category_header(option_line, lines[k + 1]):
                        k += 1
                        continue
                    
                    # Archivev8 Fix 1: Check for orphaned checkboxes within the medical history block
                    if has_orphaned_checkboxes(lines[k]) and k + 1 < len(lines):
                        orphaned_opts = associate_orphaned_labels_with_checkboxes(lines[k], lines[k + 1])
                        if orphaned_opts:
                            options.extend(orphaned_opts)
                            k += 2  # Skip both the checkbox line and label line
                            continue
                    
                    # Try compound Y/N prompts first (e.g., "Question? [ ] Yes [ ] No")
                    prompts = extract_compound_yn_prompts(option_line)
                    if prompts:
                        for p in prompts:
                            options.append((p, None))
                    else:
                        # Try inline options (e.g., "[ ] Option1 [ ] Option2")
                        inline_opts = options_from_inline_line(option_line)
                        if inline_opts:
                            options.extend(inline_opts)
                    
                    k += 1

                if len(options) >= 3: # Threshold to be considered a conditions block
                    control = {"options": [make_option(n, b) for n,b in options], "multi": True}
                    key = "medical_conditions" if cur_section == "Medical History" else "dental_conditions"
                    questions.append(Question(key, main_prompt_title, cur_section, "dropdown", control=control))
                    i = k
                    continue

        # Drop witness
        if WITNESS_RE.search(line):
            i += 1; continue

        # Signature (+ optional date)
        if "signature" in line.lower():
            if not seen_signature:
                questions.append(Question("signature", line.rstrip(":"), "Signature", "signature"))
                seen_signature = True
                # Adjacent Date (normalized title)
                if i + 1 < len(lines) and DATE_LABEL_RE.search(lines[i+1]):
                    title_dt = "Date Signed"
                    questions.append(Question(slugify(title_dt), title_dt, "Signature", "date", control={"input_type":"any"}))
                    i += 1
            i += 1; continue

        # Archivev10 Fix 1: Try multi-column checkbox grid detection first
        # This handles grids with 3+ checkboxes per line (common in medical/dental forms)
        if cur_section in {"Medical History", "Dental History"}:
            # Check if this line or upcoming lines form a multi-column checkbox grid
            multicolumn_grid = detect_multicolumn_checkbox_grid(lines, i, cur_section)
            if multicolumn_grid:
                grid_question = parse_multicolumn_checkbox_grid(lines, multicolumn_grid, debug)
                if grid_question:
                    questions.append(grid_question)
                    # Skip past the grid
                    i = max(multicolumn_grid['data_lines']) + 1
                    continue
            
            # Also check if this is a category header line followed by a grid
            # (e.g., "Appearance    Function    Habits    Previous Comfort Options")
            if not re.search(CHECKBOX_ANY, line):
                # Check if it looks like multiple column headers
                parts = re.split(r'\s{5,}', line.strip())
                if len(parts) >= 3 and all(len(p.split()) <= 4 for p in parts):
                    # Might be category headers, check if next line has multiple checkboxes
                    if i + 1 < len(lines):
                        next_checkboxes = len(list(re.finditer(CHECKBOX_ANY, lines[i + 1])))
                        if next_checkboxes >= 3:
                            # This is a category header line before a grid!
                            multicolumn_grid = detect_multicolumn_checkbox_grid(lines, i, cur_section)
                            if multicolumn_grid:
                                grid_question = parse_multicolumn_checkbox_grid(lines, multicolumn_grid, debug)
                                if grid_question:
                                    questions.append(grid_question)
                                    i = max(multicolumn_grid['data_lines']) + 1
                                    continue
        
        # Fix 4: Enhanced Table/Grid Detection - try multi-row table first
        table_info = detect_table_layout(lines, i)
        if table_info:
            # Parse entire table at once
            table_questions = parse_table_to_questions(lines, table_info, cur_section)
            questions.extend(table_questions)
            
            # Skip past the table
            i = max(table_info['data_lines']) + 1
            continue

        # Grid (existing logic for simpler cases)
        hdr_cols = looks_like_grid_header(line)
        if hdr_cols:
            ncols = len(hdr_cols)
            col_options: List[List[Tuple[str, Optional[bool]]]] = [[] for _ in range(ncols)]
            k = i + 1
            while k < len(lines) and lines[k].strip():
                row = collapse_spaced_caps(lines[k])
                if is_heading(row): break
                cells = chunk_by_columns(row, ncols)
                for cidx, cell in enumerate(cells):
                    if not cell.strip(): continue
                    opts=[]
                    if BULLET_RE.match(cell): 
                        o = option_from_bullet_line(cell); 
                        if o: opts.append(o)
                    else:
                        opts += options_from_inline_line(cell)
                    if not opts and ("," in cell or "/" in cell or ";" in cell):
                        for tok in re.split(r"[,/;]", cell):
                            tok = clean_token(tok)
                            if tok: opts.append((tok, None))
                    col_options[cidx].extend(opts)
                k += 1
            for cidx, col in enumerate(hdr_cols):
                opts = col_options[cidx]
                if not opts: continue
                options = [make_option(n,b) for (n,b) in opts]
                control = {"options": options, "multi": True}
                qkey = slugify(col)
                if insurance_scope and "insurance" in cur_section.lower():
                    qkey = f"{qkey}{insurance_scope}"
                questions.append(Question(qkey, col, cur_section, "dropdown", control=control))
            i = k; continue

        # --- Insurance ID/SSN fan-out (before other logic) ---
        fan = _insurance_id_ssn_fanout(line)
        if fan:
            for (kname, ktype, kctrl) in fan:
                qkey = _insurance_scope_key(kname, cur_section, insurance_scope, line, debug)
                questions.append(Question(qkey, CANON_LABELS.get(kname, kname.replace("_"," ").title()), "Insurance" if "insurance" in cur_section else cur_section, ktype, control=kctrl))
            if debug: print(f"  [debug] gate: insurance_fanout -> '{line}' -> ['insurance_id_number','ssn(+scope)']")
            i += 1; continue

        # Archivev15 Fix 1: Check for field label with inline checkbox option
        # Pattern: "Field Label:    <spaces>    [ ] Option text"
        # This must be checked BEFORE try_split_known_labels which incorrectly splits these lines
        # Use raw line (not collapsed) to preserve spacing
        field_checkbox_split = detect_field_with_inline_checkbox(raw)
        if field_checkbox_split:
            field_label, checkbox_option = field_checkbox_split
            
            # Create the main field (e.g., "Cell Phone")
            field_title = field_label.strip()
            field_key = slugify(field_title)
            field_itype = classify_input_type(field_title)
            
            questions.append(Question(
                field_key,
                field_title,
                cur_section,
                "input",
                control={"input_type": field_itype or "text"}
            ))
            
            # Create the checkbox field (e.g., "Yes, send me Text Message alerts")
            checkbox_title = checkbox_option.strip()
            # Use a prefix to ensure unique key that won't conflict with main field
            checkbox_key = f"opt_in_{slugify(checkbox_title)}"
            
            questions.append(Question(
                checkbox_key,
                checkbox_title,
                cur_section,
                "radio",
                control={"options": [make_option("Yes", True), make_option("No", False)]}
            ))
            
            if debug:
                print(f"  [debug] gate: field_with_inline_checkbox -> '{field_title}' + '{checkbox_title}'")
            
            i += 1
            continue

        # --- Composite / multi-label fan-out ---
        composite_labels = try_split_known_labels(line)
        if composite_labels:
            for ttl in composite_labels:
                if ttl.lower().startswith("state"):
                    qtype, ctrl = "states", {}
                elif "date" in ttl.lower() or "birth" in ttl.lower() or "dob" in ttl.lower():
                    qtype, ctrl = "date", {"input_type": classify_date_input(ttl)}
                else:
                    itype = classify_input_type(ttl)
                    qtype, ctrl = "input", ({"input_type": itype} if itype else {})
                key = slugify(ttl)
                # parent/guardian override
                key, qtype, ctrl = _emit_parent_guardian_override(ttl, key, qtype, ctrl, cur_section, insurance_scope, debug)
                # insurance scoping for SSN
                key = _insurance_scope_key(key, cur_section, insurance_scope, ttl, debug)
                if insurance_scope and "insurance" in cur_section.lower() and not key.endswith((PRIMARY_SUFFIX, SECONDARY_SUFFIX)) and key in {"ssn","insurance_id_number"}:
                    key = f"{key}{insurance_scope}"
                questions.append(Question(key, ttl, cur_section, qtype, control=ctrl))
            i += 1; continue

        # Single-checkbox → boolean radio (e.g., Responsible Party …)
        mbox = SINGLE_BOX_RE.match(line)
        if mbox and RESP_PARTY_RE.search(line):
            title = "Responsible party is someone other than patient?"
            key = slugify(title)
            if insurance_scope and "insurance" in cur_section.lower():
                key = f"{key}{insurance_scope}"
            control = {"options":[make_option("Yes",True), make_option("No",False)]}
            questions.append(Question(key, title, "Insurance", "radio", control=control))
            if debug: print(f"  [debug] gate: bool_single_box -> '{line}' -> radio Yes/No")
            i += 1; continue

        # Fix 4: Check for orphaned checkboxes (enhanced)
        if i + 1 < len(lines):
            orphaned_opts = extract_orphaned_checkboxes_and_labels(line, lines[i+1])
            if orphaned_opts:
                # Check if in medical/dental history section for condition collection
                is_condition_block = cur_section in {"Medical History", "Dental History"}
                
                # Try to find a better title from previous line
                title = "Please select all that apply:"
                if i > 0:
                    prev_line = collapse_spaced_caps(lines[i-1].strip())
                    if prev_line and not re.search(CHECKBOX_ANY, prev_line) and not is_heading(prev_line):
                        # Use previous line as title if it looks like a question
                        if prev_line.endswith('?') or prev_line.endswith(':') or len(prev_line) > 20:
                            title = prev_line.rstrip(':').strip()
                
                if is_condition_block:
                    # Add to a medical conditions dropdown
                    control = {"options": [make_option(n, b) for n, b in orphaned_opts], "multi": True}
                    key = "medical_conditions" if cur_section == "Medical History" else "dental_conditions"
                    questions.append(Question(key, title, cur_section, "dropdown", control=control))
                else:
                    # Create standalone dropdown
                    key = slugify(title)
                    control = {"options": [make_option(n, b) for n, b in orphaned_opts], "multi": True}
                    questions.append(Question(key, title, cur_section, "dropdown", control=control))
                
                if debug: print(f"  [debug] gate: orphaned_checkboxes -> found {len(orphaned_opts)} options")
                i += 2  # Skip both current and next line
                continue

        # Bullet -> terms (explanatory lists)
        if line.lstrip().startswith(("•","·")):
            terms_lines = [line]; k = i+1
            while k < len(lines) and lines[k].strip() and not is_heading(lines[k]):
                if lines[k].lstrip().startswith(("•","·")):
                    terms_lines.append(lines[k])
                else:
                    terms_lines[-1] += " " + lines[k].strip()
                k += 1
            txt_terms = " ".join(collapse_spaced_caps(x).strip() for x in terms_lines)
            questions.append(Question(
                slugify("terms_"+(terms_lines[0][:20] if terms_lines else "list")),
                "Terms", "Consent", "terms",
                control={"agree_text":"I have read and agree to the terms.","html_text":txt_terms}
            ))
            i = k; continue

        # Special: “Please share the following dates”
        if re.search(r"please\s+share\s+the\s+following\s+dates", line, re.I):
            harvested = " ".join(collapse_spaced_caps(lines[j].strip()) for j in range(i, min(i+3,len(lines))))
            for lbl in ["Cleaning","Cancer Screening","X-Rays","X Rays","Xray"]:
                if re.search(lbl.replace(" ", r"\s*"), harvested, re.I):
                    questions.append(Question(slugify(lbl), lbl, cur_section, "date", control={"input_type":"any"}))
            i += 1; continue

        # Robust 1..10 detection (pain scale etc.)
        digits = [int(x) for x in re.findall(r"\b\d+\b", line)]
        if digits and digits == list(range(1, 11)):
            title = line
            options = [{"name": str(n), "value": n} for n in range(1,11)]
            questions.append(Question(slugify(title), title, cur_section, "radio", control={"options": options}))
            i += 1; continue

        # Comms consent
        if re.search(r"\bsend me\b.*\btext\b", line, re.I):
            questions.append(Question("consent_text_alerts","Consent to Text Message alerts",cur_section,"radio",
                                      control={"options":[make_option("Yes",True),make_option("No",False)]}))
            i += 1; continue
        if re.search(r"\bsend me\b.*\bemail\b", line, re.I):
            questions.append(Question("consent_email_alerts","Consent to Email alerts",cur_section,"radio",
                                      control={"options":[make_option("Yes",True),make_option("No",False)]}))
            i += 1; continue

        # Fix 2: Enhanced "If Yes" Detection - try new pattern first
        question_text, has_followup = extract_yn_with_followup(line)
        if question_text and has_followup:
            # Create both question and follow-up using the new helper
            new_questions = create_yn_question_with_followup(question_text, cur_section)
            questions.extend(new_questions)
            if debug: print(f"  [debug] gate: yn_with_followup -> '{question_text}' + explanation field")
            i += 1
            continue
        
        # Compound Yes/No on one line (existing logic)
        compound_prompts = extract_compound_yn_prompts(line)
        emitted_compound = False
        if compound_prompts:
            for ptxt in compound_prompts:
                # Fix: Strip follow-up instructions from prompt to get clean question
                # Pattern: "Question? If yes, please explain:______" -> "Question?"
                clean_ptxt = re.sub(r'\s+(if\s+yes|if\s+so|please\s+explain|explain\s+below).*$', '', ptxt, flags=re.I).strip()
                if not clean_ptxt:
                    clean_ptxt = ptxt  # Fallback if regex removes everything
                
                key = slugify(clean_ptxt)
                if insurance_scope and "insurance" in cur_section.lower():
                    key = f"{key}{insurance_scope}"
                control = {"options":[make_option("Yes",True),make_option("No",False)]}
                
                # Fix 2: Enhanced follow-up field detection
                create_follow_up = False
                if re.search(IF_GUIDANCE_RE, line):
                    control["extra"] = {"type":"Input","hint":"If yes, please explain"}
                    create_follow_up = True
                
                # Check same line for "if yes, please explain"
                if re.search(r'\b(if\s+yes|please\s+explain|if\s+so|explain\s+below)\b', line, re.I):
                    create_follow_up = True
                
                # Check next line for follow-up indicators
                if i + 1 < len(lines):
                    next_line = collapse_spaced_caps(lines[i+1].strip())
                    if re.search(r'^\s*(if\s+yes|please\s+explain|explain|comment|list|details?)', next_line, re.I):
                        create_follow_up = True
                
                # Create follow-up field if needed with conditional
                if create_follow_up:
                    follow_up_key = f"{key}_explanation"
                    # Check if not already created
                    if not any(q.key == follow_up_key for q in questions):
                        follow_up_q = Question(
                            follow_up_key,
                            "Please explain",
                            cur_section,
                            "input",
                            control={"input_type": "text", "hint": "Please provide details"}
                        )
                        # Add conditional to only show if Yes
                        follow_up_q.conditional_on = [(key, "yes")]
                        questions.append(follow_up_q)
                
                questions.append(Question(key, clean_ptxt, cur_section, "radio", control=control))
                emitted_compound = True
            if re.search(r"name\s+of\s+school", line, re.I):
                questions.append(Question("name_of_school","Name of School",cur_section,"input",control={"input_type":"text"}))
        if emitted_compound:
            i += 1; continue

        # Enhancement 2: Enhanced inline option detection
        # Detect questions with inline text options: "Question? Y or N", "Sex M or F", etc.
        inline_option_match = detect_inline_text_options(line)
        if inline_option_match:
            question_text, option_type, options = inline_option_match
            
            # Create question from the text before the options
            title = question_text.strip()
            if title.endswith('?'):
                title = title[:-1].strip()
            
            key = slugify(title)
            
            # Create control with detected options
            control = {"options": [{"name": opt[0], "value": opt[1]} for opt in options]}
            
            questions.append(Question(key, title, cur_section, "radio", control=control))
            
            if debug:
                print(f"  [debug] gate: inline_text_options -> '{title}' with {len(options)} options")
            
            i += 1
            continue
        
        # Archivev12 Fix 3: Special handling for Sex/Gender with text options (M or F) - LEGACY fallback
        # Keep for backward compatibility, but the new detect_inline_text_options should catch these
        sex_match = re.search(r'\b(sex|gender)\s*[:\-]?\s*(?:M\s*or\s*F|M/F|Male/Female|Mor\s*F)', line, re.I)
        if sex_match:
            key = "sex"
            title = sex_match.group(1).title()
            control = {
                "options": [
                    {"name": "Male", "value": "male"},
                    {"name": "Female", "value": "female"},
                    {"name": "Other", "value": "other"},
                    {"name": "Prefer not to self identify", "value": "not_say"}
                ]
            }
            questions.append(Question(key, title, cur_section, "radio", control=control))
            i += 1
            continue
        
        # Archivev12 Fix 4: Special handling for "Please Circle One:" marital status
        marital_match = re.search(r'(?:please\s+)?circle\s+one\s*:?\s*(.*?)$', line, re.I)
        if marital_match:
            # Extract options from the rest of the line
            options_text = marital_match.group(1).strip()
            # Common marital status options
            marital_options = []
            for opt in ['Single', 'Married', 'Divorced', 'Separated', 'Widowed', 'Widow']:
                if opt.lower() in options_text.lower():
                    if opt == 'Widow':
                        opt = 'Widowed'  # Normalize
                    if opt not in [o['name'] for o in marital_options]:
                        marital_options.append({"name": opt, "value": opt.lower()})
            
            if marital_options:
                # Add standard options if not present
                if not any(o['name'] == 'Prefer not to say' for o in marital_options):
                    marital_options.append({"name": "Prefer not to say", "value": "not say"})
                
                control = {"options": marital_options}
                questions.append(Question("marital_status", "Marital Status", cur_section, "radio", control=control))
                i += 1
                continue


        # Option harvesting for a single prompt (incl. “hear about us”)
        opts_inline = options_from_inline_line(line)
        opts_block: List[Tuple[str, Optional[bool]]] = []
        j = i + 1
        # collect bullets immediately below
        while j < len(lines):
            cand = collapse_spaced_caps(lines[j])
            if not cand.strip(): break
            o = option_from_bullet_line(cand)
            if o: opts_block.append(o); j += 1; continue
            # NEW: Also collect inline checkbox options from following lines (Fix 1 enhancement)
            inline_opts = options_from_inline_line(cand)
            if inline_opts:  # Any checkboxes found
                # Archivev20 Fix 5: Don't collect options from a line that has its own label
                # (e.g., "Marital Status: [ ] Married [ ] Single" should not be collected by "Ext#")
                bracket_pos = cand.find('[')
                
                # Archivev20 Fix 10: Enhanced label detection - check for label even without colon
                # Patterns: "Sex [ ] Male [ ] Female" or "Marital Status: [ ] Married"
                line_has_own_label = False
                if bracket_pos > 0:
                    text_before_bracket = cand[:bracket_pos].strip()
                    # Has label if: contains colon OR has meaningful text (3+ chars, not just numbers/symbols)
                    if ':' in text_before_bracket:
                        line_has_own_label = True
                    elif len(text_before_bracket) >= 3 and re.search(r'[A-Za-z]{3,}', text_before_bracket):
                        # Has at least 3 letters in a row (meaningful word), likely a label
                        line_has_own_label = True
                
                # Archivev20 Fix 8: Also don't collect if line starts with checkbox (standalone checkbox field)
                # (e.g., "[ ] Yes, send me Text Message alerts" should not be collected by "Zip:")
                line_starts_with_checkbox = bracket_pos <= 2  # Allow for leading whitespace
                
                if line_has_own_label or (len(inline_opts) == 1 and line_starts_with_checkbox):
                    # This line has its own label OR is a standalone checkbox field, don't collect
                    break
                
                if len(inline_opts) >= 2:  # Multiple options on this line - definitely collect
                    opts_block.extend(inline_opts)
                    j += 1
                    continue
                elif len(inline_opts) == 1 and opts_block:  # Single option but we already have options - continue collecting
                    opts_block.extend(inline_opts)
                    j += 1
                    continue
            # No valid options found on this line - check if it's a continuation or break
            if not re.search(CHECKBOX_ANY, cand):  # No checkboxes at all
                break
            # Has checkboxes but no valid labels - might be orphaned checkboxes, continue
            j += 1
            continue

        title = line.rstrip(":").strip()
        is_hear = bool(HEAR_ABOUT_RE.search(title))
        
        # Fix 1: If current line starts with checkbox and we have opts_block, look back for title
        if opts_block and re.match(r'^\s*' + CHECKBOX_ANY, line):
            if i > 0:
                prev_line = collapse_spaced_caps(lines[i-1].strip())
                if prev_line and not re.search(CHECKBOX_ANY, prev_line) and not is_heading(prev_line):
                    title = prev_line.rstrip(':').strip()
                    is_hear = bool(HEAR_ABOUT_RE.search(title))

        # “How did you hear...” — aggressively collect same line + next two non-heading lines
        if is_hear and not (opts_inline or opts_block):
            # Fix 1: Check if next line has inline checkboxes - if so, skip and let next line handle it
            # Fix 1: Check if next line(s) have inline checkboxes - skip blanks
            check_idx = i + 1
            while check_idx < len(lines) and not lines[check_idx].strip():
                check_idx += 1  # Skip blank lines
            if check_idx < len(lines):
                next_line_check = lines[check_idx].strip()
                if next_line_check and re.search(CHECKBOX_ANY, next_line_check):
                    next_opts_check = options_from_inline_line(next_line_check)
                    if len(next_opts_check) >= 2:
                        # Next line will handle this, skip for now
                        i += 1
                        continue
            
            # same line split
            for tok in re.split(r"[,/;]", title):
                tok = clean_token(tok)
                if tok and tok.lower() not in {"how did you hear about us", "referred by"}:
                    opts_inline.append((tok, None))
            k = i + 1
            extra_lines = 0
            while k < len(lines) and extra_lines < 2:
                cand = collapse_spaced_caps(lines[k]).strip()
                if not cand or is_heading(cand): break
                ob = option_from_bullet_line(cand)
                if ob:
                    opts_block.append(ob); k += 1; continue
                for tok in re.split(r"[,/;]", cand):
                    tok = clean_token(tok)
                    if tok: opts_block.append((tok, None))
                k += 1; extra_lines += 1
            j = max(j, k)

        # Priority 2.1: Check for multi-field lines (e.g., "Phone: Mobile ___ Home ___ Work ___")
        multi_fields = detect_multi_field_line(line)
        if multi_fields:
            if debug:
                print(f"  [debug] multi-field detected: {line[:60]}... -> {len(multi_fields)} fields")
            for field_key, field_title in multi_fields:
                # Determine input type based on base field
                input_type = "text"
                if "phone" in field_key or "fax" in field_key:
                    input_type = "phone"
                elif "email" in field_key:
                    input_type = "email"
                questions.append(Question(field_key, field_title, cur_section, "input",
                                          control={"input_type": input_type}))
            i += 1
            continue
        
        # Category 1 Fix 1.2: Check for fill-in-blank fields
        prev_line_text = lines[i-1] if i > 0 else None
        fill_in_blank = detect_fill_in_blank_field(line, prev_line_text)
        if fill_in_blank:
            field_key, field_title = fill_in_blank
            if debug:
                print(f"  [debug] fill-in-blank detected: {line[:60]}... -> {field_key}")
            questions.append(Question(field_key, field_title, cur_section, "input",
                                      control={"input_type": "text"}))
            i += 1
            continue
        
        # Priority 2.3: Check for inline checkbox with continuation text
        inline_checkbox_field = detect_inline_checkbox_with_text(line)
        if inline_checkbox_field:
            field_key, field_title, field_type = inline_checkbox_field
            if debug:
                print(f"  [debug] inline checkbox with text: {line[:60]}... -> {field_key}")
            # Create a boolean/radio field with the option and description
            questions.append(Question(field_key, field_title, cur_section, field_type,
                                      control={"options": [make_option("Yes", True), make_option("No", False)]}))
            i += 1
            continue

        # Simple labeled fields
        if STATE_LABEL_RE.match(title):
            key = slugify(title or "state")
            if insurance_scope and "insurance" in cur_section.lower(): key = f"{key}{insurance_scope}"
            questions.append(Question(key, title or "State", cur_section, "states", control={}))
            i += 1; continue

        # Production readiness: Remove trailing underscores before date detection
        title_for_check = re.sub(r'_+$', '', title).strip()
        if DATE_LABEL_RE.search(title_for_check):
            key = slugify(title or "date")
            if insurance_scope and "insurance" in cur_section.lower(): key = f"{key}{insurance_scope}"
            # Archivev18 Fix 1: Clean date field titles to remove template artifacts
            clean_title = clean_field_title(title) if title else "Date"
            questions.append(Question(key, clean_title, cur_section, "date",
                                      control={"input_type": classify_date_input(title)}))
            i += 1; continue

        collected = opts_inline or opts_block
        if collected:
            # Fix 1: Clean title if it has inline checkboxes or concatenated options
            clean_title = title
            
            # If we have inline options (especially multiple ones), check if title needs cleaning
            if opts_inline and len(opts_inline) >= 2:
                # Archivev19 Fix 3: Only look back if current line doesn't have a clear label before checkboxes
                # Extract text before first checkbox to see if we have a meaningful title
                extracted_title = extract_title_from_inline_checkboxes(line)
                
                # Archivev20 Fix 3: If we extracted a title with proper formatting (has colon), ALWAYS use it
                # Don't look back even if it's short - this fixes "Marital Status:" being replaced by "Ext#"
                has_proper_label = extracted_title and ':' in line[:line.find('[') if '[' in line else len(line)]
                
                # Phase 4 Fix: Common short field names that should be accepted even without colon
                common_short_fields = {'sex', 'gender', 'age', 'dob', 'ssn', 'name', 'city', 'state', 'zip'}
                is_common_short = extracted_title and extracted_title.lower().strip() in common_short_fields
                
                # If we extracted a meaningful title from the current line, use it
                if extracted_title and len(extracted_title) >= 3 and (has_proper_label or is_common_short):
                    # Current line has "Label: [ ] options" format OR is a common short field - use the extracted label
                    clean_title = extracted_title
                elif extracted_title and len(extracted_title) >= 5:
                    # Extracted title is long enough even without colon
                    clean_title = extracted_title
                else:
                    # Title likely includes the options. Look back for a better title (skip blank lines).
                    lookback_idx = i - 1
                    while lookback_idx >= 0 and not lines[lookback_idx].strip():
                        lookback_idx -= 1  # Skip blank lines
                    if lookback_idx >= 0:
                        prev_line = collapse_spaced_caps(lines[lookback_idx].strip())
                        if prev_line and not re.search(CHECKBOX_ANY, prev_line) and not is_heading(prev_line):
                            # Use previous line if it looks like a question/prompt
                            if len(prev_line) >= 5:
                                clean_title = prev_line.rstrip(':').strip()
            
            # If title still has checkbox markers, try to extract clean text
            if re.search(CHECKBOX_ANY, clean_title):
                extracted = extract_title_from_inline_checkboxes(clean_title)
                # Archivev12 Fix: Allow short field names like "Sex", "Age"
                if extracted and len(extracted) >= 2:
                    clean_title = extracted
                else:
                    # Couldn't extract - fallback to looking back or generic title
                    if i > 0 and clean_title == title:  # Haven't already looked back
                        prev_line = collapse_spaced_caps(lines[i-1].strip())
                        if prev_line and not re.search(CHECKBOX_ANY, prev_line) and not is_heading(prev_line):
                            clean_title = prev_line.rstrip(':').strip()
                        else:
                            clean_title = "Please select"
                    else:
                        clean_title = "Please select"
            
            # Archivev21 Fix 7: Clean title before creating key to fix OCR errors in keys
            cleaned_question_title = clean_field_title(clean_title)
            
            lowset = {n.lower() for (n,_b) in collected}
            if {"yes","no"} <= lowset or lowset <= YESNO_SET:
                control = {"options":[make_option("Yes",True), make_option("No",False)]}
                if re.search(IF_GUIDANCE_RE, cleaned_question_title):
                    control["extra"] = {"type":"Input","hint":"If yes, please explain"}
                    # --- Fix 2: Add separate input for "if yes" (enhanced) ---
                    if j < len(lines):
                        next_line = collapse_spaced_caps(lines[j].strip())
                        if re.search(r"\b(list|explain|if so|name of)\b", next_line, re.I):
                            follow_up_title = f"{cleaned_question_title} - Details"
                            follow_up_key = slugify(follow_up_title)
                            questions.append(Question(follow_up_key, follow_up_title, cur_section, "input", control={"input_type": "text"}))
                key = slugify(cleaned_question_title)
                if insurance_scope and "insurance" in cur_section.lower(): key = f"{key}{insurance_scope}"
                questions.append(Question(key, cleaned_question_title, cur_section, "radio", control=control))
            else:
                make_radio = bool(SINGLE_SELECT_TITLES_RE.search(cleaned_question_title))
                options = [make_option(n, b) for (n,b) in collected]
                if not options and ("," in cleaned_question_title or "/" in cleaned_question_title or ";" in cleaned_question_title):
                    for tok in re.split(r"[,/;]", cleaned_question_title):
                        tok = clean_token(tok)
                        if tok: options.append(make_option(tok, None))
                control: Dict = {"options": options}
                if not make_radio:
                    control["multi"] = True
                if is_hear:
                    control["extra"] = {"type":"Input","hint":"Other (please specify)"}
                    if (REFERRED_BY_RE.search(cleaned_question_title) or (j < len(lines) and REFERRED_BY_RE.search(lines[j]))):
                        questions.append(Question("referred_by","Referred by",cur_section,"input",control={"input_type":"text"}))
                key = slugify(cleaned_question_title)
                if insurance_scope and "insurance" in cur_section.lower(): key = f"{key}{insurance_scope}"
                qtype = "radio" if make_radio else "dropdown"
                questions.append(Question(key, cleaned_question_title, cur_section, qtype, control=control))
            i = j if not opts_inline else i + 1
            continue

        # Long paragraph → terms
        para = [lines[i]]; k = i+1
        while k < len(lines) and lines[k].strip() and not BULLET_RE.match(lines[k].strip()):
            if is_heading(lines[k]): break
            # Stop collecting if we hit a yes/no question pattern (don't include these in terms)
            if extract_compound_yn_prompts(lines[k]):
                break
            para.append(lines[k]); k += 1
        joined = " ".join(collapse_spaced_caps(x).strip() for x in para)
        if len(joined) > 250 and joined.count(".") >= 2:
            chunks: List[List[str]] = []; cur: List[str] = []
            for s in para:
                if is_heading(s.strip()) and cur:
                    chunks.append(cur); cur=[s]
                else:
                    cur.append(s)
            if cur: chunks.append(cur)
            for idx2, chunk in enumerate(chunks):
                t = " ".join(collapse_spaced_caps(x).strip() for x in chunk).strip()
                if not t: continue
                questions.append(Question(
                    slugify((chunk[0].strip() if is_heading(chunk[0].strip()) else (title or "terms")) + (f"_{idx2+1}" if idx2 else "")),
                    (collapse_spaced_caps(chunk[0].strip().rstrip(":")) if is_heading(chunk[0].strip()) else "Terms"),
                    "Consent",
                    "terms",
                    control={"agree_text":"I have read and agree to the terms.","html_text":t},
                ))
            i = k; continue

        # Default: input
        # Fix 1: Skip if next line has inline options that will use this as title
        # BUT only if the next line doesn't have its own label (e.g., "Label: [ ] options")
        if i + 1 < len(lines):
            next_line = lines[i + 1].strip()
            if next_line and re.search(CHECKBOX_ANY, next_line):
                # Check if next line has inline options
                next_opts = options_from_inline_line(next_line)
                if len(next_opts) >= 2:
                    # Archivev20 Fix 4: Only skip if next line doesn't have its own label
                    # Check if next line has a colon before the checkboxes (indicates it has its own label)
                    bracket_pos = next_line.find('[')
                    has_own_label = bracket_pos > 0 and ':' in next_line[:bracket_pos]
                    
                    if not has_own_label:
                        # Next line will create a field using this line as title, so skip
                        i += 1
                        continue
        
        # Fix 2: Skip obvious business/practice address lines (Archivev20)
        # These should have been filtered by scrub_headers_footers but some slip through
        # Examples: "3138 N Lincoln Ave Chicago, IL", "60657", "Chicago, IL 60632"
        # Archivev22 Enhancement: Also skip document titles and section headers that slipped through
        skip_patterns = [
            r'^\d{5}$',  # Just a zip code
            r'^\d+\s+[NS]?\s*\w+\s+(Ave|Avenue|Rd|Road|St|Street|Blvd|Boulevard)\b',  # Street address
            r',\s*[A-Z]{2}\s+\d{5}$',  # City, State Zip
            r'^\d+[A-Z]?\s+S\s+\w+\s+(Ave|Rd|St|Blvd)',  # Address starting with number
            r'\w+\s*\.\s*(com|org|net|us|info|dental)\b',  # Website domain (with optional space before dot)
            r'^\d{3}[-.]\d{3}[-.]\d{4}$',  # Phone number (standalone)
            r'\b\d{3}[-.]\d{3}[-.]\d{4}\b',  # Phone number anywhere in text
            r'@\s*\w+\s*\.\s*\w+',  # Email address (with optional spaces)
            r'\(pg\.\s*\d+\)',  # Page number reference
            r'^please\s+(ensure|note|read|remember)',  # Instructions
            r'^[*]+',  # Lines starting with asterisks (often instructions)
        ]
        should_skip = any(re.search(pattern, title, re.I) for pattern in skip_patterns)
        
        # Archivev22 Enhancement: Skip document titles that look like form headers
        # (e.g., "ENDODONTIC INFORMATION AND CONSENT FORM", "Informed Consent for Tooth Extraction")
        if not should_skip and len(title.split()) >= 4:
            title_lower = title.lower()
            # Check for form title keywords
            has_form_keywords = any(kw in title_lower for kw in ['consent', 'form', 'information', 'agreement', 'authorization', 'release', 'disclosure'])
            # Must be title case or all caps (not mixed case sentences)
            is_title_case = title.istitle() or title.isupper()
            
            if has_form_keywords and is_title_case:
                should_skip = True
                if debug: print(f"  [debug] skipping document title: '{title[:60]}'")
        
        # Archivev22 Enhancement: Skip lines that look like section headers describing content
        # (e.g., "Endodontic (Root Canal) Treatment, Endodontic Surgery, Anesthetics, and Medications")
        if not should_skip and len(title) > 60 and title.count(',') >= 2:
            # Long lines with multiple commas are likely descriptive headers, not field labels
            should_skip = True
            if debug: print(f"  [debug] skipping descriptive header: '{title[:60]}'")
        
        if should_skip:
            i += 1
            continue
        
        # Archivev21 Fix 2: Clean field title before creating Question (removes underscores, artifacts)
        cleaned_title = clean_field_title(title)
        itype = classify_input_type(cleaned_title)
        key = slugify(cleaned_title)
        # parent/guardian routing
        key, qtype, ctrl = _emit_parent_guardian_override(cleaned_title, key, "input", {"input_type": itype} if itype else {}, cur_section, insurance_scope, debug)
        # employer patient-first: only map to insurance_employer if insurance context tokens are present
        if key == "employer":
            if "insurance" in cur_section.lower() or re.search(r"\b(insured|subscriber|policy|member|insurance)\b", cleaned_title.lower()):
                pass  # allow later dictionary to map to insurance_employer if template title says so
            else:
                if debug: print(f"  [debug] gate: employer_patient_first -> '{cleaned_title}' -> employer (patient)")
        key = _insurance_scope_key(key, cur_section, insurance_scope, cleaned_title, debug)
        if insurance_scope and "insurance" in cur_section.lower() and not key.endswith((PRIMARY_SUFFIX, SECONDARY_SUFFIX)) and key in {"ssn","insurance_id_number"}:
            key = f"{key}{insurance_scope}"
        questions.append(Question(key, cleaned_title, cur_section, qtype, control=ctrl))
        i += 1

    # Final sanitation & signature rule
    def is_instructional_text(text: str) -> bool:
        """
        Archivev18 Fix 2: Detect instructional/paragraph text that shouldn't be captured as fields.
        Archivev22 Enhancement: Better detection of informational bullet points and long descriptions.
        Returns True if the text is likely instructions/guidance rather than a field label.
        """
        text_lower = text.lower().strip()
        original_text = text.strip()
        
        # Check if this is an informational bullet point (starts with bullet symbol)
        # Common in consent forms describing risks/complications
        if original_text.startswith(('●', '•', '·')):
            # These are typically risk descriptions, not fillable fields
            # Look for keywords common in risk/complication lists
            risk_keywords = [
                'adverse', 'reaction', 'numbness', 'tingling', 'bleeding', 'infection',
                'swelling', 'fracture', 'damage', 'injury', 'pain', 'sensitivity',
                'complication', 'risk', 'temporary', 'permanent', 'may result', 'may cause',
                'can lead', 'potential', 'possible', 'delayed healing', 'post-operative',
                'post treatment', 'involving', 'involvement'
            ]
            if any(keyword in text_lower for keyword in risk_keywords):
                return True
        
        # Check for common instructional phrases
        instructional_phrases = [
            "thank you for",
            "medication that you may be taking",
            "could have an important",
            "interrelationship with",
            "health problems that you may have",
            "please read",
            "please ensure",
            "please note",
            "i understand that providing incorrect",
            "to the best of my knowledge",
            "the questions on this form have been",
            "accurately answered",
            "providing incorrect information can be",
            "although dental professionals",
            "your mouth is a part of",
            "have been explained to me",
            "i understand that",
            "these treatments include",
            "alternative methods",
            "risks and complications",
            "may include (but",
            "are not limited to",
            "has performed a thorough examination",
            "has determined that",
        ]
        
        if any(phrase in text_lower for phrase in instructional_phrases):
            return True
        
        # If text is very long (>120 chars) and contains connecting phrases, likely instructional
        if len(text) > 120:
            connecting_phrases = [" that you ", " which ", " could ", " should ", " would ", " may ", " can "]
            if any(phrase in text_lower for phrase in connecting_phrases):
                return True
        
        # Check for document titles (all caps or title case, contains form keywords)
        if len(original_text.split()) >= 4:
            is_title_case = original_text.istitle() or original_text.isupper()
            title_keywords = ['consent', 'form', 'information', 'agreement', 'authorization', 'release', 'disclosure']
            has_form_keywords = any(keyword in text_lower for keyword in title_keywords)
            
            # Also check for common section header patterns
            section_keywords = ['risks', 'benefits', 'alternatives', 'procedures', 'treatment']
            has_section_keywords = any(keyword in text_lower for keyword in section_keywords)
            
            if is_title_case and (has_form_keywords or has_section_keywords):
                return True
        
        # Phase 4 Fix 10: Enhanced document title detection
        # Catch patterns like "Informed Consent for [Procedure Name]"
        if text_lower.startswith('informed consent for'):
            return True
        
        return False
    
    def is_junk(q: Question) -> bool:
        t = q.title.strip().lower()
        return (q.key == "q" or len(q.title.strip()) <= 1 or
                t in {"<<<", ">>>", "-", "—", "continued on back side"} or
                is_instructional_text(q.title))
    questions = [q for q in questions if not is_junk(q)]
    questions = [q for q in questions if not WITNESS_RE.search(q.title)]

    sig_idxs = [idx for idx,q in enumerate(questions) if q.type=="signature"]
    if not sig_idxs:
        questions.append(Question("signature","Signature","Signature","signature"))
    elif len(sig_idxs) > 1:
        for idx in reversed(sig_idxs[1:]): questions.pop(idx)

    return questions

# ---------- Validation / normalization

def ensure_control_present(q: Question) -> None:
    if q.control is None: q.control = {}
    if q.type == "radio":    q.control.setdefault("options", [])
    if q.type == "dropdown": q.control.setdefault("options", []); q.control.setdefault("multi", True)
    if q.type == "date":     q.control.setdefault("input_type", "any")
    if q.type == "input":    q.control.setdefault("input_type", "text")
    if q.type == "terms":
        q.control.setdefault("agree_text","I have read and agree to the terms.")
        q.control.setdefault("html_text","")

def fill_missing_option_values(q: Question) -> None:
    if q.type not in ("radio","dropdown"): return
    opts = q.control.get("options") or []
    fixed=[]
    for opt in opts:
        name = (opt.get("name") or "").strip() or "Option"
        val  = opt.get("value")
        if val in (None, ""):
            vlow = name.strip().lower()
            if vlow == "yes": val = True
            elif vlow == "no": val = False
            else: val = slugify(name, 80)
        fixed.append({"name": name, "value": val})
    q.control["options"] = fixed

def _semantic_dedupe(payload: List[dict]) -> List[dict]:
    """
    Remove duplicate simple inputs that are identical semantically (same title/section/type/input_type).
    
    Archivev8 Fix 3: Skip deduplication for conditional fields (they can have same title).
    """
    seen: Set[Tuple[str,str,str,str]] = set()
    out: List[dict] = []
    for q in payload:
        if q.get("type") == "input":
            # Archivev8 Fix 3: Don't dedupe conditional fields
            if q.get("if") or "conditional" in q.get("key", "").lower() or "_explanation" in q.get("key", "").lower():
                out.append(q)
                continue
            
            itype = (q.get("control") or {}).get("input_type","text")
            sig = (q.get("title","").strip().lower(), q.get("section",""), "input", itype)
            if sig in seen:
                continue
            seen.add(sig)
        out.append(q)
    return out

def dedupe_keys(questions: List[Question]) -> None:
    seen: Dict[str,int] = {}
    for q in questions:
        base = "signature" if q.type=="signature" else (q.key or "q")
        if q.type=="signature":
            q.key = "signature"; continue
        if base not in seen: seen[base]=1; q.key=base
        else: seen[base]+=1; q.key=f"{base}_{seen[base]}"

def validate_form(questions: List[Question]) -> List[str]:
    errs=[]
    for q in questions:
        if q.type not in ALLOWED_TYPES:
            errs.append(f"Unsupported type for {q.key}: {q.type}")
    sig = [q for q in questions if q.type=="signature"]
    if len(sig)!=1 or sig[0].key!="signature":
        errs.append("Signature rule violated (need exactly one with key='signature').")
    for q in questions:
        if q.type in ("radio","dropdown"):
            for opt in q.control.get("options", []):
                if opt.get("value") in (None,""):
                    errs.append(f"Empty option value in {q.key}")
    return errs

def questions_to_json(questions: List[Question]) -> List[Dict]:
    for q in questions:
        ensure_control_present(q)
        fill_missing_option_values(q)
    dedupe_keys(questions)
    errs = validate_form(questions)
    if errs:
        print("Validation warnings:", *errs, sep="\n  ", file=sys.stderr)
    payload = []
    for q in questions:
        item = {"key": q.key, "title": q.title, "section": q.section,
                "optional": q.optional, "type": q.type, "control": q.control or {}}
        
        # Fix 2: Add conditional "if" property for follow-up fields
        if hasattr(q, 'conditional_on') and q.conditional_on:
            # Convert conditional_on to "if" array format
            item["if"] = [{"key": cond_key, "value": cond_val} for cond_key, cond_val in q.conditional_on]
        
        payload.append(item)
    
    payload = _semantic_dedupe(payload)
    return payload

# ---------- Post-processing helpers

def _norm_title(s: str) -> str:
    s = (s or "").lower()
    s = re.sub(r"[^\w\s]", "", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def postprocess_merge_hear_about_us(payload: List[dict]) -> List[dict]:
    idxs = [i for i,q in enumerate(payload) if HEAR_ABOUT_RE.search(q.get("title",""))]
    if len(idxs) <= 1:
        return payload
    keep = idxs[0]
    all_opts: Dict[str, dict] = {}
    extras: List[dict] = []
    for i in idxs:
        q = payload[i]
        for o in (q.get("control",{}).get("options") or []):
            k = normalize_opt_name(o.get("name",""))
            if not k: continue
            all_opts[k] = {"name": o.get("name",""), "value": o.get("value", slugify(o.get("name",""),80))}
        extra = q.get("control",{}).get("extra")
        if extra: extras.append(extra)
    payload[keep]["control"]["options"] = list(all_opts.values())
    payload[keep]["control"]["multi"] = True
    if extras:
        payload[keep]["control"]["extra"] = {"type":"Input","hint":"Other (please specify)"}
    for i in sorted(idxs[1:], reverse=True):
        payload.pop(i)
    return payload

# ---------- Fix 3: Enhanced Malformed Conditions Detection

def is_malformed_condition_field(field: dict) -> bool:
    """
    Detect if a field is a malformed medical/dental condition field.
    
    Criteria:
    - Type is dropdown with multi=True
    - Title is unusually long (5+ words) or contains multiple condition keywords
    - Options contain medical/health terms
    
    Examples of malformed titles:
    - "Artificial Angina (chest Heart pain) Valve Thyroid Disease..."
    - "Bleeding, Swollen, Irritated gums Tobacco"
    - "Heart Surgery Ulcers (Stomach) Dizziness AIDS"
    """
    if field.get('type') != 'dropdown':
        return False
    
    if not field.get('control', {}).get('multi'):
        return False
    
    title = field.get('title', '')
    title_lower = title.lower()
    
    # Check 1: Title has multiple medical condition keywords
    condition_keywords = [
        'diabetes', 'cancer', 'heart', 'disease', 'arthritis', 'hepatitis',
        'asthma', 'anxiety', 'depression', 'ulcer', 'thyroid', 'kidney',
        'liver', 'tuberculosis', 'hiv', 'aids', 'stroke', 'bleeding',
        'anemia', 'glaucoma', 'angina', 'valve', 'neurological'
    ]
    
    keyword_count = sum(1 for kw in condition_keywords if kw in title_lower)
    
    # If title has 3+ condition keywords, likely malformed
    if keyword_count >= 3:
        return True
    
    # Check 2: Title is very long and has some condition keywords
    word_count = len(title.split())
    if word_count >= 8 and keyword_count >= 2:
        return True
    
    # Check 3: Title contains multiple capitalized words that look like conditions
    capitalized_words = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', title)
    if len(capitalized_words) >= 4 and keyword_count >= 1:
        return True
    
    return False


def postprocess_consolidate_medical_conditions(payload: List[dict]) -> List[dict]:
    """
    Enhanced version that consolidates both well-formed and malformed condition dropdowns,
    plus individual checkbox/radio fields that look like medical conditions (Fix 1).
    """
    def looks_condition(opt_name: str) -> bool:
        w = _norm_title(opt_name)
        return any(t in w for t in _COND_TOKENS)
    
    # Medical condition keywords for identifying individual condition fields
    CONDITION_KEYWORDS = [
        'diabetes', 'cancer', 'heart', 'disease', 'arthritis', 'hepatitis',
        'asthma', 'anxiety', 'depression', 'ulcer', 'thyroid', 'kidney',
        'liver', 'tuberculosis', 'hiv', 'aids', 'stroke', 'bleeding',
        'anemia', 'glaucoma', 'angina', 'valve', 'neurological', 'alzheimer',
        'blood pressure', 'cholesterol', 'pacemaker', 'chemotherapy', 'radiation',
        'convulsion', 'seizure', 'epilepsy', 'migraine', 'allergy'
    ]
    
    # Separate handling for malformed dropdowns, well-formed dropdowns, and individual checkboxes
    malformed_indices = []
    wellformed_groups_by_section: Dict[str, List[int]] = defaultdict(list)
    individual_condition_indices: Dict[str, List[int]] = defaultdict(list)
    
    for i, q in enumerate(payload):
        section = q.get('section', 'General')
        
        # Check if malformed
        if is_malformed_condition_field(q):
            malformed_indices.append(i)
            continue
        
        # Check if well-formed medical condition field (original logic)
        if (q.get('type') == 'dropdown' and 
            q.get('control', {}).get('multi', False) and 
            q.get('section') in {'Medical History', 'Dental History'}):
            
            opts = q.get('control', {}).get('options') or []
            if len(opts) >= 5 and sum(looks_condition(o.get('name', '')) for o in opts) >= 3:
                wellformed_groups_by_section[section].append(i)
                continue
        
        # Check if individual checkbox/radio that looks like a medical condition (Fix 1)
        if q.get('type') in ['checkbox', 'radio'] and section in {'Medical History', 'General'}:
            title = q.get('title', '').lower()
            # Check if title contains medical condition keywords
            has_condition_keyword = any(kw in title for kw in CONDITION_KEYWORDS)
            # Or if it's a short title (1-4 words) in Medical History section
            is_short_medical = section == 'Medical History' and len(title.split()) <= 4
            
            if has_condition_keyword or is_short_medical:
                individual_condition_indices[section].append(i)
    
    # Consolidate malformed fields
    if malformed_indices:
        # Extract all options from malformed fields
        all_options = []
        sections = set()
        
        for idx in malformed_indices:
            field = payload[idx]
            sections.add(field.get('section', 'Medical History'))
            
            # Extract options from the malformed field
            opts = field.get('control', {}).get('options', [])
            for opt in opts:
                opt_name = opt.get('name', '')
                opt_value = opt.get('value', '')
                
                # Clean up option name
                opt_name = opt_name.strip()
                
                # Skip if too short or looks like junk
                if len(opt_name) < 3:
                    continue
                
                # Add to consolidated list if not duplicate
                if opt_name not in [o['name'] for o in all_options]:
                    all_options.append({
                        'name': opt_name,
                        'value': opt_value if opt_value else slugify(opt_name, 80)
                    })
        
        # Create consolidated field
        if all_options:
            consolidated_section = list(sections)[0] if len(sections) == 1 else 'Medical History'
            
            consolidated_field = {
                'key': 'medical_conditions_consolidated',
                'type': 'dropdown',
                'title': 'Do you have or have you had any of the following medical conditions?',
                'section': consolidated_section,
                'optional': False,
                'control': {
                    'options': sorted(all_options, key=lambda x: x['name']),
                    'multi': True
                }
            }
            
            # Replace first malformed field with consolidated
            payload[malformed_indices[0]] = consolidated_field
            
            # Remove other malformed fields
            for idx in sorted(malformed_indices[1:], reverse=True):
                payload.pop(idx)
    
    # Original consolidation logic for well-formed fields
    for section, groups in list(wellformed_groups_by_section.items()):
        if len(groups) <= 1:
            continue
        
        keep = groups[0]
        seen: Set[str] = set()
        merged: List[dict] = []
        
        for i in groups:
            for o in (payload[i].get('control', {}).get('options') or []):
                name = SPELL_FIX.get(o.get('name', ''), o.get('name', ''))
                norm = normalize_opt_name(name)
                if not norm or norm in seen:
                    continue
                seen.add(norm)
                merged.append({'name': name, 'value': o.get('value', slugify(name, 80))})
        
        if section == 'Medical History':
            payload[keep]['title'] = 'Medical Conditions'
            payload[keep]['key'] = 'medical_conditions'
        payload[keep]['control']['options'] = merged
        
        for i in sorted(groups[1:], reverse=True):
            payload.pop(i)
    
    # New: Consolidate individual checkbox/radio fields that are medical conditions (Fix 1)
    for section, indices in list(individual_condition_indices.items()):
        # Only consolidate if we have 5+ individual condition fields
        if len(indices) < 5:
            continue
        
        # Create consolidated dropdown
        consolidated_options = []
        seen_names: Set[str] = set()
        
        for idx in indices:
            field = payload[idx]
            title = field.get('title', '').strip()
            
            # Normalize the title for duplicate detection
            norm_title = normalize_opt_name(title)
            if norm_title and norm_title not in seen_names:
                seen_names.add(norm_title)
                consolidated_options.append({
                    'name': title,
                    'value': slugify(title, 80)
                })
        
        if consolidated_options:
            # Replace first field with consolidated dropdown
            payload[indices[0]] = {
                'key': 'medical_conditions' if section == 'Medical History' else 'dental_conditions',
                'type': 'dropdown',
                'title': 'Do you have or have you had any of the following?',
                'section': section,
                'optional': False,
                'control': {
                    'options': sorted(consolidated_options, key=lambda x: x['name']),
                    'multi': True
                }
            }
            
            # Remove other individual condition fields
            for idx in sorted(indices[1:], reverse=True):
                payload.pop(idx)
    
    return payload

def postprocess_signature_uniqueness(payload: List[dict]) -> List[dict]:
    sig_idx = [i for i,q in enumerate(payload) if q.get("type")=="signature"]
    if not sig_idx:
        payload.append({"key":"signature","title":"Signature","section":"Signature","type":"signature","control":{}})
    elif len(sig_idx) > 1:
        for i in sorted(sig_idx[1:], reverse=True):
            payload.pop(i)
        payload[sig_idx[0]].update({"key":"signature","title":"Signature","section":"Signature","type":"signature"})
    else:
        i = sig_idx[0]
        payload[i].update({"key":"signature","title":"Signature","section":"Signature","type":"signature"})
    return payload

def postprocess_rehome_by_key(payload: List[dict], dbg: Optional[DebugLogger]=None) -> List[dict]:
    ins_keys = ("insurance_", "insured", "policy", "group", "member id", "id number")
    demo_keys = ("last_name","first_name","mi","date_of_birth","address","city","state","zipcode","email","phone",
                 "mobile_phone","home_phone","work_phone","drivers_license","employer","occupation","parent_")
    for q in payload:
        t = _norm_title(q.get("title",""))
        k = q.get("key","")
        sec = q.get("section","General")
        if (sec not in {"Insurance"} and (t.count("insurance") or any(s in k for s in ins_keys))):
            q["section"] = "Insurance"
            if dbg: dbg.gate(f"rehome -> Insurance :: {q.get('title','')}")
        if (sec not in {"Patient Information","Insurance"} and (any(k.startswith(d) for d in demo_keys) or "parent" in k)):
            q["section"] = "Patient Information"
            if dbg: dbg.gate(f"rehome -> Patient Information :: {q.get('title','')}")
    return payload

def postprocess_infer_sections(payload: List[dict], dbg: Optional[DebugLogger] = None) -> List[dict]:
    """
    Reassign fields from 'General' to more specific sections based on content.
    Uses keyword matching to identify medical and dental questions.
    """
    # Strong keywords that alone indicate medical history
    STRONG_MEDICAL_KEYWORDS = [
        'physician', 'hospitalized', 'surgery', 'surgical', 'operation',
        'medication', 'medicine', 'prescription', 
        'allergy', 'allergic',
        # Common disease/condition patterns
        'hiv', 'aids', 'diabetes', 'cancer', 'heart', 'blood pressure',
        'hepatitis', 'asthma', 'arthritis', 'alzheimer', 'anemia'
    ]
    
    MEDICAL_KEYWORDS = [
        'doctor', 'hospital', 
        'drug', 'pills',
        'illness', 'disease', 'condition', 'diagnosis',
        'reaction', 'symptom', 'discomfort', 'health',
        'care now', 'taking any', 'have you had', 'have you ever'
    ]
    
    DENTAL_KEYWORDS = [
        'tooth', 'teeth', 'gum', 'gums',
        'dental', 'dentist', 'orthodontic', 'orthodontist',
        'cleaning', 'cavity', 'cavities', 'crown', 'filling',
        'bite', 'jaw', 'tmj', 'smile'
    ]
    
    for item in payload:
        if item.get('section') == 'General':
            title_lower = item.get('title', '').lower()
            key_lower = item.get('key', '').lower()
            combined = title_lower + ' ' + key_lower
            
            # Check for strong medical keywords (single match is enough)
            has_strong_medical = any(kw in combined for kw in STRONG_MEDICAL_KEYWORDS)
            
            # Count regular keyword matches
            medical_score = sum(1 for kw in MEDICAL_KEYWORDS if kw in combined)
            dental_score = sum(1 for kw in DENTAL_KEYWORDS if kw in combined)
            
            # Reassign based on signals
            # Strong keyword alone is enough for medical history
            if has_strong_medical and dental_score == 0:
                if dbg:
                    dbg.gate(f"section_inference -> Medical History :: {item.get('title', '')} (strong keyword match)")
                item['section'] = 'Medical History'
            # Or 2+ regular keywords
            elif medical_score >= 2 and medical_score > dental_score:
                if dbg:
                    dbg.gate(f"section_inference -> Medical History :: {item.get('title', '')} (score={medical_score})")
                item['section'] = 'Medical History'
            elif dental_score >= 2 and dental_score > medical_score:
                if dbg:
                    dbg.gate(f"section_inference -> Dental History :: {item.get('title', '')} (score={dental_score})")
                item['section'] = 'Dental History'
    
    return payload

def postprocess_consolidate_duplicates(payload: List[dict], dbg: Optional[DebugLogger] = None) -> List[dict]:
    """
    Remove duplicate fields, keeping the one in the most appropriate section.
    Focuses on common fields like DOB, phone, email, address, SSN.
    """
    # Common fields that might be duplicated with their preferred section
    COMMON_FIELDS = {
        'date_of_birth': 'Patient Information',
        'dob': 'Patient Information',
        'phone': 'Patient Information',
        'mobile_phone': 'Patient Information',
        'home_phone': 'Patient Information',
        'work_phone': 'Patient Information',
        'cell_phone': 'Patient Information',
        'email': 'Patient Information',
        'address': 'Patient Information',
        'ssn': 'Patient Information',
        'social_security': 'Patient Information',
    }
    
    # Track seen keys and their indices
    seen_keys = {}
    to_remove = []
    
    for i, item in enumerate(payload):
        key = item.get('key', '')
        # Normalize key by removing numeric suffixes and scope markers
        key_base = re.sub(r'_\d+$', '', key)  # Remove _2, _3, etc.
        key_base = re.sub(r'__\w+$', '', key_base)  # Remove __primary, __secondary, etc.
        
        # Check if this is a common field that might be duplicated
        if key_base in COMMON_FIELDS:
            if key_base in seen_keys:
                # Duplicate found - determine which to keep
                prev_idx = seen_keys[key_base]
                prev_section = payload[prev_idx].get('section', 'General')
                curr_section = item.get('section', 'General')
                preferred_section = COMMON_FIELDS[key_base]
                
                if curr_section == preferred_section and prev_section != preferred_section:
                    # Current is in preferred section, remove previous
                    to_remove.append(prev_idx)
                    seen_keys[key_base] = i
                    if dbg:
                        dbg.gate(f"duplicate_consolidation -> Removed {key_base} from {prev_section}, kept in {curr_section}")
                elif prev_section == preferred_section and curr_section != preferred_section:
                    # Previous is in preferred section, remove current
                    to_remove.append(i)
                    if dbg:
                        dbg.gate(f"duplicate_consolidation -> Removed {key} from {curr_section}, kept {key_base} in {prev_section}")
                else:
                    # Neither in preferred or both in preferred, keep first occurrence
                    to_remove.append(i)
                    if dbg:
                        dbg.gate(f"duplicate_consolidation -> Removed duplicate {key} from {curr_section}")
            else:
                seen_keys[key_base] = i
    
    # Remove duplicates in reverse order to maintain indices
    for idx in sorted(set(to_remove), reverse=True):
        payload.pop(idx)
    
    return payload


def postprocess_consolidate_malformed_grids(payload: List[dict], dbg: Optional[DebugLogger] = None) -> List[dict]:
    """
    Archivev10 Fix 4: Consolidate malformed multi-column checkbox fields.
    
    Detects fields with concatenated condition names in titles (e.g.,
    "Radiation Therapy Jaundice Jaw Joint Pain") and consolidates them
    into cleaner multi-select fields.
    """
    # Identify malformed fields in Medical/Dental History
    malformed_indices = []
    
    for i, item in enumerate(payload):
        section = item.get('section', '')
        title = item.get('title', '')
        item_type = item.get('type', '')
        
        # Only check dropdown fields in Medical/Dental History
        if section not in {'Medical History', 'Dental History'}:
            continue
        
        if item_type != 'dropdown':
            continue
        
        # Check if title looks malformed (3+ medical/dental terms concatenated)
        # Split title into words and count capitalized medical terms
        words = title.split()
        capitalized_words = [w for w in words if w and w[0].isupper() and len(w) > 2]
        
        # Check for medical/dental keywords
        medical_keywords = [
            'therapy', 'disease', 'disorder', 'condition', 'illness', 'syndrome',
            'pain', 'fever', 'bleeding', 'valve', 'joint', 'respiratory',
            'cardiovascular', 'hematologic', 'psychiatric', 'gastrointestinal',
            'arthritis', 'diabetes', 'asthma', 'seizure', 'allergy', 'nursing',
            'teeth', 'grinding', 'clenching', 'sucking', 'biting', 'chewing',
            'discolored', 'worn', 'crooked', 'spaces', 'overbite', 'sensitivity',
            'anesthesia', 'sulfa', 'drugs'
        ]
        
        title_lower = title.lower()
        keyword_count = sum(1 for kw in medical_keywords if kw in title_lower)
        
        # Enhanced detection: Malformed if title lacks connecting words
        # Good titles have "please mark", "do you", "have you", etc.
        has_instruction = bool(re.search(r'\b(please|mark|any|conditions|apply|do you|have you)\b', title_lower))
        
        # Malformed if: (4+ capitalized words AND no instructions) OR (4+ keywords AND no instructions)
        is_malformed = False
        if not has_instruction:
            if len(capitalized_words) >= 4 or keyword_count >= 4:
                is_malformed = True
        
        if is_malformed:
            # Also check that options exist and are reasonable
            options = item.get('control', {}).get('options', [])
            if len(options) >= 2:
                malformed_indices.append(i)
                if dbg:
                    dbg.gate(f"malformed_grid_detected -> '{title[:60]}...' with {len(options)} options")
    
    # If we found malformed fields, consolidate them by section
    if not malformed_indices:
        return payload
    
    # Group malformed fields by section
    by_section = {}
    for idx in malformed_indices:
        section = payload[idx].get('section', 'General')
        if section not in by_section:
            by_section[section] = []
        by_section[section].append(idx)
    
    # Consolidate each section's malformed fields
    to_remove = []
    new_fields = []
    
    for section, indices in by_section.items():
        # Skip if only 1 field (not worth consolidating)
        if len(indices) <= 1:
            continue
        
        # Collect all options from malformed fields
        all_options = []
        for idx in indices:
            options = payload[idx].get('control', {}).get('options', [])
            all_options.extend(options)
            to_remove.append(idx)
        
        # Remove duplicates
        seen = set()
        unique_options = []
        for opt in all_options:
            opt_name = opt.get('name', '') if isinstance(opt, dict) else opt
            if opt_name and opt_name.lower() not in seen:
                seen.add(opt_name.lower())
                unique_options.append(opt)
        
        # Create consolidated field
        if len(unique_options) >= 5:
            if section == "Medical History":
                title = "Medical History - Please mark any conditions that apply"
                key = "medical_conditions_consolidated"
            elif section == "Dental History":
                title = "Dental History - Please mark any conditions that apply"
                key = "dental_conditions_consolidated"
            else:
                title = f"{section} - Please mark any that apply"
                key = slugify(title)
            
            new_field = {
                'key': key,
                'title': title,
                'section': section,
                'type': 'dropdown',
                'optional': False,
                'control': {
                    'options': unique_options,
                    'multi': True
                }
            }
            
            new_fields.append((indices[0], new_field))  # Insert at position of first malformed field
            
            if dbg:
                dbg.gate(f"malformed_grid_consolidated -> {len(indices)} fields into '{title}' with {len(unique_options)} options")
    
    # Remove malformed fields in reverse order
    for idx in sorted(set(to_remove), reverse=True):
        payload.pop(idx)
    
    # Insert consolidated fields
    for insert_pos, new_field in sorted(new_fields, reverse=True):
        # Adjust insert position if we've already removed items
        adjusted_pos = insert_pos
        for removed_idx in sorted(to_remove):
            if removed_idx < insert_pos:
                adjusted_pos -= 1
        payload.insert(adjusted_pos, new_field)
    
    return payload


def postprocess_consolidate_continuation_options(payload: List[dict], dbg: Optional[DebugLogger] = None) -> List[dict]:
    """
    Archivev18 Fix 4: Consolidate checkbox fields that are continuations of previous fields.
    
    Pattern: Field with title that's just concatenated option names (e.g., "Local Anesthesia Sulfa Drugs Other")
    following a field with a proper question title in the same section.
    
    Example:
    Field 1: "Are you allergic to any of the following?" with options [Aspirin, Penicillin, ...]
    Field 2: "Local Anesthesia Sulfa Drugs Other" with options [Local Anesthesia, Sulfa Drugs, Other]
    
    Should consolidate Field 2's options into Field 1 and remove Field 2.
    """
    i = 0
    while i < len(payload):
        item = payload[i]
        title = item.get('title', '')
        
        # Check if this field looks like concatenated options (3+ capitalized words, no question marks/colons)
        # and is a dropdown with multiple options
        words = title.split()
        capitalized = [w for w in words if w and w[0].isupper()]
        
        is_concatenated = (
            len(capitalized) >= 3 and 
            '?' not in title and 
            not title.endswith(':') and
            item.get('type') in ('dropdown', 'radio')
        )
        
        if is_concatenated and i > 0:
            prev_item = payload[i - 1]
            prev_title = prev_item.get('title', '').lower()
            
            # Check if previous field is in same section and is a question about selecting/checking items
            same_section = item.get('section') == prev_item.get('section')
            is_selection_question = any(phrase in prev_title for phrase in [
                'allergic', 'any of the following', 'select', 'choose', 'check', 'mark'
            ])
            prev_is_dropdown = prev_item.get('type') in ('dropdown', 'radio')
            
            if same_section and is_selection_question and prev_is_dropdown:
                # Consolidate: add current field's options to previous field
                current_options = item.get('control', {}).get('options', [])
                prev_options = prev_item.get('control', {}).get('options', [])
                
                # Check if options in current field match parts of its title (confirmation it's concatenated)
                option_names = [opt.get('name', '') if isinstance(opt, dict) else opt for opt in current_options]
                title_has_options = sum(1 for opt_name in option_names if opt_name in title)
                
                if title_has_options >= 2:  # At least 2 option names appear in title
                    # Merge options
                    combined_options = prev_options + current_options
                    
                    # Remove duplicates
                    seen = set()
                    unique_options = []
                    for opt in combined_options:
                        opt_name = opt.get('name', '') if isinstance(opt, dict) else opt
                        if opt_name and opt_name.lower() not in seen:
                            seen.add(opt_name.lower())
                            unique_options.append(opt)
                    
                    prev_item['control']['options'] = unique_options
                    
                    if dbg:
                        dbg.gate(f"continuation_consolidated -> Merged '{title}' ({len(current_options)} opts) into '{prev_item['title']}' (total: {len(unique_options)} opts)")
                    
                    # Remove current field
                    payload.pop(i)
                    continue
        
        i += 1
    
    return payload


def postprocess_clean_overflow_titles(payload: List[dict], dbg: Optional[DebugLogger] = None) -> List[dict]:
    """
    Archivev11 Fix 3: Clean up field titles that have column overflow artifacts.
    
    Removes known label patterns that appear at the end of titles due to
    text extraction extending into adjacent columns.
    """
    LABEL_PATTERNS = [
        r'\s+Frequency\s*$',           # "Alcohol Frequency", "Drugs Frequency"
        r'\s+How\s+much\s*$',          # "How much"
        r'\s+How\s+long\s*$',          # "How long"
        r'\s+Comments?\s*:?\s*$',      # "Comments", "Comment:"
        r'\s+Additional\s+Comments?\s*:?\s*$',  # "Additional Comments"
        r'\s+Pattern\s*$',             # "Pattern"
        r'\s+Conditions?\s*$',         # "Conditions"
    ]
    
    for item in payload:
        title = item.get('title', '')
        original_title = title
        
        # Check if title ends with a known label pattern
        for pattern in LABEL_PATTERNS:
            if re.search(pattern, title, re.I):
                # Truncate at the pattern
                title = re.sub(pattern, '', title, flags=re.I).strip()
                
                if dbg and title != original_title:
                    dbg.gate(f"overflow_title_cleaned -> '{original_title}' → '{title}'")
                
                item['title'] = title
                break
    
    return payload


def postprocess_make_explain_fields_unique(payload: List[dict], dbg: Optional[DebugLogger] = None) -> List[dict]:
    """
    Archivev11 Fix 5: Make duplicate titles unique by adding context.
    
    When multiple fields have the same title in a section, add context from:
    - Preceding field (for explanation/follow-up fields)
    - Numeric suffix (for repeated fields like "Insured's Name")
    - Key information (as a last resort)
    """
    # Track title occurrences by section
    title_counts = {}
    
    for i, item in enumerate(payload):
        title = item.get('title', '').strip()
        section = item.get('section', 'General')
        key = item.get('key', '')
        
        # Create a unique identifier for this title in this section
        section_title = f"{section}:{title}"
        
        # Archivev18 Fix 3: Handle generic explanation titles even on first occurrence
        generic_titles = ['please explain', 'explanation', 'details', 'comments', 'if yes, please explain']
        is_generic = any(gt in title.lower() for gt in generic_titles)
        
        # If this is a generic title following a yes/no question, improve it immediately
        if is_generic and i > 0:
            prev_item = payload[i - 1]
            prev_title = prev_item.get('title', '')
            
            # If previous field is a yes/no question, use it as context
            if any(yn in prev_title.lower() for yn in ['yes or no', 'y or n', 'have you', 'are you', 'do you']):
                # Use full parent question title, but truncate if too long
                # Remove trailing question mark and colon for better readability
                context = prev_title.rstrip('?:').strip()
                
                # If context is too long (>60 chars), use first few words
                if len(context) > 60:
                    words = context.split()[:5]
                    context = ' '.join(words)
                
                new_title = f"{context} - Please explain"
                
                if dbg:
                    dbg.gate(f"unique_title -> '{title}' → '{new_title}' (context)")
                
                item['title'] = new_title
                # Update title for duplicate tracking
                title = new_title
                section_title = f"{section}:{title}"
        
        # Check if this is a duplicate
        if section_title in title_counts:
            count = title_counts[section_title]
            title_counts[section_title] = count + 1
            
            # Note: Generic titles are now handled above, before duplicate check
            
            # Strategy 2: For repeated fields (like Insurance fields), add numeric suffix
            # Check if key has a numeric suffix or scope marker
            key_has_suffix = bool(re.search(r'(_\d+|__\w+)$', key))
            if key_has_suffix:
                # Extract suffix info
                if '__primary' in key:
                    new_title = f"{title} (Primary)"
                elif '__secondary' in key:
                    new_title = f"{title} (Secondary)"
                elif re.search(r'_(\d+)$', key):
                    match = re.search(r'_(\d+)$', key)
                    num = match.group(1)
                    new_title = f"{title} #{num}"
                else:
                    new_title = f"{title} ({count + 1})"
                
                if dbg:
                    dbg.gate(f"unique_title -> '{title}' → '{new_title}' (suffix)")
                
                item['title'] = new_title
                continue
            
            # Strategy 3: Fallback - add numeric suffix
            new_title = f"{title} ({count + 1})"
            
            if dbg:
                dbg.gate(f"unique_title -> '{title}' → '{new_title}' (numeric)")
            
            item['title'] = new_title
        else:
            title_counts[section_title] = 1
    
    return payload

# ---------- Dictionary application + reporting

@dataclass
class Stats:
    total: int
    used: int
    counts_by_section: Dict[str,int]
    counts_by_type: Dict[str,int]
    matches: List[MatchEvent]
    near_misses: List[MatchEvent]

def apply_templates_and_count(payload: List[dict], catalog: Optional[TemplateCatalog], dbg: DebugLogger) -> Tuple[List[dict], int]:
    """
    Apply template matching and count matches.
    
    Enhanced to preserve conditional follow-up fields (Archivev8 Fix 3).
    """
    if not catalog:
        return payload, 0
    
    used = 0
    out: List[dict] = []
    
    for q in payload:
        # Archivev8 Fix 3: Check if this is a conditional/explanation field
        # Archivev15 Fix: Also skip opt-in preference fields (inline checkbox options)
        # These should not have templates applied to avoid breaking conditional relationships or changing keys
        is_conditional_field = (
            bool(q.get("conditional_on")) or
            "_explanation" in q.get("key", "") or
            "_followup" in q.get("key", "") or
            "_details" in q.get("key", "") or
            q.get("key", "").startswith("opt_in_") or  # Archivev15: Skip opt-in preference fields
            (q.get("title", "").lower().strip() in ["please explain", "explanation", "details", "comments"])
        )
        
        if is_conditional_field:
            # Skip template matching for conditional fields
            out.append(q)
            if dbg.enabled and not q.get("key", "").startswith("opt_in_"):
                print(f"  [debug] template: skipping conditional field '{q.get('key')}' to preserve relationship")
            continue
        
        # Normal template matching for non-conditional fields
        fr = catalog.find(q.get("key"), q.get("title"), parsed_q=q)
        if fr.tpl:
            used += 1
            merged = merge_with_template(q, fr.tpl, scope_suffix=fr.scope)
            out.append(merged)
            dbg.log(MatchEvent(q.get("title",""), q.get("key",""), q.get("section",""), fr.tpl.get("key"), fr.reason, fr.score, fr.coverage))
        else:
            out.append(q)
            if fr.reason == "near":
                dbg.log_near(MatchEvent(q.get("title",""), q.get("key",""), q.get("section",""), fr.best_key, "near", fr.score, fr.coverage))
    
    out = _dedupe_keys_dicts(out)
    return out, used

def write_stats_sidecar(out_path: Path, payload: List[dict], used: int, dbg: DebugLogger, 
                        extraction_metadata: Optional[dict] = None, parsing_metadata: Optional[dict] = None):
    """
    Write enhanced statistics sidecar file.
    
    Priority 8.1: Enhanced Debug Output and Stats
    - Adds extraction metadata (file type, size, character count)
    - Adds parsing statistics (grids detected, options parsed)
    - Lists unmatched fields that might need dictionary entries
    """
    total = len(payload)
    counts_by_section = defaultdict(int)
    counts_by_type = defaultdict(int)
    for q in payload:
        counts_by_section[q.get("section","General")] += 1
        counts_by_type[q.get("type","input")] += 1
    
    # Priority 8.1: Collect unmatched fields for dictionary enhancement suggestions
    unmatched_fields = []
    if dbg.enabled:
        matched_keys = {ev.matched_key for ev in dbg.events if hasattr(ev, 'matched_key') and ev.matched_key}
        for q in payload:
            q_key = q.get("key", "")
            if q_key not in matched_keys:
                unmatched_fields.append({
                    "key": q_key,
                    "title": q.get("title", ""),
                    "section": q.get("section", ""),
                    "type": q.get("type", "")
                })
    
    stats = {
        "file": out_path.name,
        "total_items": total,
        "reused_from_dictionary": used,
        "reused_pct": (used/total*100.0 if total else 0.0),
        "counts_by_section": dict(counts_by_section),
        "counts_by_type": dict(counts_by_type),
        "matches": [ev.__dict__ for ev in dbg.events] if dbg.enabled else [],
        "near_misses": [ev.__dict__ for ev in dbg.near_misses] if dbg.enabled else [],
        "gates": dbg.gates if dbg.enabled else [],
    }
    
    # Priority 8.1: Add extraction metadata if available
    if extraction_metadata:
        stats["extraction"] = extraction_metadata
    
    # Priority 8.1: Add parsing metadata if available
    if parsing_metadata:
        stats["parsing"] = parsing_metadata
    
    # Priority 8.1: Add unmatched fields suggestions
    if unmatched_fields:
        stats["unmatched_fields"] = unmatched_fields
        stats["dictionary_suggestions"] = {
            "count": len(unmatched_fields),
            "message": "Consider adding these fields to dental_form_dictionary.json for better matching"
        }
    
    sidecar = out_path.with_suffix(".stats.json")
    sidecar.write_text(json.dumps(stats, ensure_ascii=False, indent=2), encoding="utf-8")

# ---------- IO

def process_one(txt_path: Path, out_dir: Path, catalog: Optional[TemplateCatalog] = None, debug: bool=False) -> Optional[Path]:
    raw = read_text_file(txt_path)
    if not raw.strip():
        print(f"[skip] empty file: {txt_path.name}")
        return None
    
    # Priority 8.1: Collect extraction metadata
    extraction_metadata = {
        "source_file": txt_path.name,
        "file_size_bytes": txt_path.stat().st_size if txt_path.exists() else 0,
        "character_count": len(raw),
        "line_count": len(raw.split('\n'))
    }
    
    # Parse → normalize JSON
    questions = parse_to_questions(raw, debug=debug)
    
    # Priority 8.1: Collect parsing metadata
    parsing_metadata = {
        "raw_questions_parsed": len(questions),
        "sections_detected": len(set(q.section for q in questions)),
        "unique_sections": sorted(set(q.section for q in questions))
    }
    
    payload = questions_to_json(questions)

    # Post-process merges + normalization
    payload = postprocess_merge_hear_about_us(payload)
    payload = postprocess_consolidate_medical_conditions(payload)
    payload = postprocess_signature_uniqueness(payload)

    # Apply templates + count
    dbg = DebugLogger(enabled=debug)
    payload, used = apply_templates_and_count(payload, catalog, dbg)

    # Re-home after template merge
    payload = postprocess_rehome_by_key(payload, dbg=dbg)
    
    # New post-processing steps (Archivev9 fixes)
    payload = postprocess_infer_sections(payload, dbg=dbg)
    payload = postprocess_consolidate_duplicates(payload, dbg=dbg)
    
    # Archivev10 Fix 4: Consolidate malformed grid fields
    payload = postprocess_consolidate_malformed_grids(payload, dbg=dbg)
    
    # Archivev11 Fix 3: Clean up column overflow in field titles
    payload = postprocess_clean_overflow_titles(payload, dbg=dbg)
    
    # Archivev18 Fix 4: Consolidate continuation checkbox options
    payload = postprocess_consolidate_continuation_options(payload, dbg=dbg)
    
    # Archivev11 Fix 5: Make generic "Please explain" fields unique
    payload = postprocess_make_explain_fields_unique(payload, dbg=dbg)

    out_path = out_dir / (txt_path.stem + ".modento.json")
    out_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")

    total = len(payload)
    pct = (used * 100 // total) if total else 0
    print(f"[✓] {txt_path.name} -> {out_path.name} ({total} items)")
    print(f"    ↳ reused {used}/{total} from dictionary ({pct}%)")

    if debug:
        dbg.print_summary()
    write_stats_sidecar(out_path, payload, used, dbg, extraction_metadata, parsing_metadata)
    return out_path

def process_one_wrapper(args_tuple):
    """
    Wrapper for process_one to support multiprocessing.
    
    Priority 6.1: Parallel Processing Support
    - Enables parallel processing of multiple forms
    - Returns tuple of (success, filename, error_message)
    """
    txt_path, out_dir, dict_path, debug = args_tuple
    try:
        # Load catalog in each worker (can't pickle catalog across processes)
        catalog = None
        if dict_path and dict_path.exists():
            try:
                catalog = TemplateCatalog.from_path(dict_path)
            except Exception:
                pass  # Silently ignore catalog errors in workers
        
        process_one(txt_path, out_dir, catalog=catalog, debug=debug)
        return (True, txt_path.name, None)
    except Exception as e:
        return (False, txt_path.name, str(e))


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--in",  dest="in_dir",  default=DEFAULT_IN_DIR,  help="Folder with extracted .txt files (default: output)")
    ap.add_argument("--out", dest="out_dir", default=DEFAULT_OUT_DIR, help="Folder to write JSONs (default: JSONs)")
    ap.add_argument("--debug", action="store_true", help="Verbose debug logs + near-miss reporting; write *.stats.json sidecars")
    ap.add_argument("--jobs", type=int, default=1, help="Number of parallel jobs (default: 1 for sequential). Use -1 for CPU count.")
    args = ap.parse_args()

    in_dir = Path(args.in_dir); out_dir = Path(args.out_dir)
    if not in_dir.exists():
        print(f"ERROR: input folder not found: {in_dir}", file=sys.stderr); sys.exit(2)
    out_dir.mkdir(parents=True, exist_ok=True)

    # Load dictionary path (will be loaded in each worker if parallel)
    dict_path = Path(__file__).resolve().parent.parent / "dental_form_dictionary.json"
    
    txts = sorted([p for p in in_dir.rglob("*.txt") if p.is_file()])
    if not txts:
        print(f"WARNING: no .txt files found under {in_dir}")
        return
    
    # Priority 6.1: Determine number of jobs
    num_jobs = args.jobs
    if num_jobs == -1:
        import multiprocessing
        num_jobs = multiprocessing.cpu_count()
    
    # Sequential processing (default)
    if num_jobs <= 1:
        # Load dictionary once for sequential processing
        catalog: Optional[TemplateCatalog] = None
        if dict_path.exists():
            try:
                catalog = TemplateCatalog.from_path(dict_path)
            except Exception as e:
                print(f"[warn] dictionary unavailable ({e}). Proceeding without templates.")
        else:
            print(f"[warn] dictionary file not found at {dict_path.name}. Proceeding without templates.")
        
        for p in txts:
            try:
                process_one(p, out_dir, catalog=catalog, debug=args.debug)
            except Exception as e:
                print(f"[x] failed on {p.name}: {e}", file=sys.stderr)
    
    # Parallel processing (Priority 6.1)
    else:
        import multiprocessing
        print(f"Processing {len(txts)} file(s) with {num_jobs} parallel jobs...")
        
        # Prepare arguments for workers
        work_items = [(p, out_dir, dict_path, args.debug) for p in txts]
        
        # Process in parallel
        failed_files = []
        with multiprocessing.Pool(processes=num_jobs) as pool:
            results = pool.map(process_one_wrapper, work_items)
        
        # Report results
        successful = sum(1 for success, _, _ in results if success)
        for success, filename, error_msg in results:
            if not success:
                failed_files.append((filename, error_msg))
                print(f"[x] failed on {filename}: {error_msg}", file=sys.stderr)
        
        print(f"\n✅ Completed: {successful}/{len(txts)} files processed successfully")
        if failed_files:
            print(f"❌ Failed: {len(failed_files)} file(s) - see errors above")

if __name__ == "__main__":
    main()
